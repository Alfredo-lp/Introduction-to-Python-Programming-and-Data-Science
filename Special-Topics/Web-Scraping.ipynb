{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An Introduction to Web Scraping\n",
    "\n",
    "How you can use python to extract or scrape simple text elements such as images, text, and tables from a web page."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making a request\n",
    "\n",
    "In the context of the web, a `request` is the act of connecting to some web address and performing an action. There are many possible types of requests. The most common, and the one we will be using in this lecture, is the `GET` request which you are likely quite familiar with already. A `GET` request is simply the act of downloading the content of the web address you are connected to: it's what you do everytime you browse the web!\n",
    "\n",
    "In python, we can use the [`requests`](http://docs.python-requests.org/en/latest/user/quickstart/) package to crawl (load) webpages and download (scrape) their contents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "response = requests.get(\"http://httpbin.org/html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Methods from the `requests` package return `Response` objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the most important properties of the response is its status code, which is printed by default but which we can also get explicitly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(response.status_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The status code, indicates what happened to our request.\n",
    "In this case we got a **200**, which means that all went well, and we successfully connected to the web address we wanted and downloaded its contents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(response.url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the web page's actual content, we access the Response.text variable, which contains the raw HTML source code of the page (more on this later) as one giant string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The folks at http.org have quite the sense of humour...\n",
    "\n",
    "Unfortunately thing don't always work out this nicely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "requests.get(\"http://httpbin.org/totaly-fake-webpage\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oops.\n",
    "We got a **404** code which indicates that, **although the domain exists (the part before .org)**, the particular webpage you are trying to access does not.\n",
    "\n",
    "Here are some of the most common status codes you might encounter:\n",
    "* 200, **OK**. Request was successful\n",
    "* 303, **See Other**. Page redirected to another URL. Your web browser automatically fetches the new URL but web crawlers do not usually do this unless you specify it.\n",
    "* 401 **Unauthorized**. The URL requires authentication (e.g. password) which was not provided or was incorrect.\n",
    "* 404, **Not Found**. The URL does not exist\n",
    "* 500 **Internal Server Error**. The server is having _unexpected_ problems and the web page is down.\n",
    "* 503 **Service Unavailable**. The web page is down, likely for server maintenance.\n",
    "\n",
    "More codes: http://en.wikipedia.org/wiki/List_of_HTTP_status_codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that **if the domain itself does not exist** then the `GET` request will not even connect and we get a very different error: a `ConnectionError`. This error comes with a veeery long traceback so to keep the demonstration simple I will just wrap the request in  a `try...except` statement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    response = requests.get(\"http://www.totaly-fake-domain-not-even-close.com/\")\n",
    "except requests.exceptions.ConnectionError:\n",
    "    print(\"This is not the domain you are looking for\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we know how to scrape webpages, we can move on to the next step: analyzing the page's HTML source code.\n",
    "\n",
    "...you know what HTML is, right?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Detour: A (very brief) intro to HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, maybe you don't know what HTML is. Or maybe you've accidentally viewed the source code of a webpage and wondered if you just caught a computer virus. Well, you didn't. Let me explain.\n",
    "\n",
    "HTML is a markup language for describing web documents. It stands for **H**yper **T**ext **M**arkup **L**anguage. HTML, together with CSS (**C**ascading **S**tyle **S**heets for _styling_ web documents) and Javascript (for _animating_ web documents), is the language that is used to construct web pages.\n",
    "\n",
    "HTML documents are built using a series of HTML _tags_. Each tag describes a different type of content. Web pages are built by putting together different tags.\n",
    "\n",
    "This is the general HTML tag structure:\n",
    "\n",
    "```html\n",
    "<tagname tag_attribute1=\"attribute1value1 attribute1value2\" tag_attribute2=\"attribute2value1\">tag contents</tagname>\n",
    "```\n",
    "* Tags (usually) have both a start (or opening) tag, <tagname> and an end (or closing) tag, </tagname>\n",
    "* Tags can also have attributes which are declared _inside_ the opening tag.\n",
    "* The actual tag _content_ goes inbetween the opening and closing tags."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tags can be contained (nested) inside other tags, which defines relationships between them:\n",
    "\n",
    "```html\n",
    "<parent>\n",
    "  <brother></brother>\n",
    "  <sister>\n",
    "    <grandson></grandson>\n",
    "  </sister>\n",
    "</parent>\n",
    "```\n",
    "\n",
    "* `<parent>` is the _parent_ tag of `<brother>` and `<sister>`\n",
    "* `<brother>` and `<sister>` are the _children_ or _direct descendant_ tags of `<parent>`\n",
    "* `<brother>`, `<sister>`, and `<grandson>` are the _descendant_ tags of `<parent>`\n",
    "* `<brother>` and `<sister>` are _sibling_ tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a very simple web document:\n",
    "\n",
    "```html\n",
    "<!DOCTYPE html>\n",
    "<html>\n",
    "  <head>\n",
    "    <title>Page Title</title> \n",
    "  </head>\n",
    "\n",
    "  <body>\n",
    "    <h1>My First Heading</h1>\n",
    "    <p>My first paragraph.</p>\n",
    "  </body>\n",
    "</html> \n",
    "```\n",
    "\n",
    "Here, `<h1>` and `<p>` are sibling tags, `<body>` is their parent tag, and all three are descendent tags of `<html>`\n",
    "\n",
    "When you access any URL, your browser (Chrome, Firefox, Safari, IE, etc.) is actually reading a document such as this one and using the tags within the document to decide how to render the page for you.\n",
    "\n",
    "Jupyter is able to render a (python) string of HTML code as real HTML in the notebook itself!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "first_html = \"\"\"\n",
    "<!DOCTYPE html>\n",
    "<html>\n",
    "  <head>\n",
    "    <title>Page Title</title>\n",
    "  </head>\n",
    "  \n",
    "  <body>\n",
    "    <h1>My First Heading</h1>\n",
    "    <p>My first paragraph.</p>\n",
    "  </body>\n",
    "\n",
    "</html> \n",
    "\"\"\"\n",
    "\n",
    "HTML(first_html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's look at what the different tags mean:\n",
    "\n",
    "```html\n",
    "<!-- This is how you write a comment in HTML. Comments will not show up in the browser -->\n",
    "\n",
    "<!-- This line simply identifies the document type to be HTML-->\n",
    "<!DOCTYPE html>\n",
    "<!-- Content between <html> and </html> tags define everything about the document-->\n",
    "<html>\n",
    "  <!-- Tags inside the <head> are not rendered but provide general information about the document -->\n",
    "  <head>\n",
    "    <!-- Like the <title> tag which provides a title that appears in the browser's title and tab bars -->\n",
    "    <title>Page Title</title>\n",
    "  </head>\n",
    "  \n",
    "  <!-- Anything inside the <body> tags describes visible page content -->\n",
    "  <body>\n",
    "    <!-- The <h1> defines a header. The number defines the size of the header. -->\n",
    "    <!-- There are 6 levels of headers: <h1> to <h6> -->\n",
    "    <!-- The higher the number, the lower the font used to display it. -->\n",
    "    <h1>My First Heading</h1>\n",
    "    <!-- The <p> represents a paragraph.-->\n",
    "    <p>My first paragraph.</p>\n",
    "  </body>\n",
    "</html>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Different levels of headers**\n",
    "\n",
    "```html\n",
    "<h1>This is heading 1</h1>\n",
    "<h2>This is heading 2</h2>\n",
    "<h3>This is heading 3</h3>\n",
    "<h4>This is heading 4</h4>\n",
    "<h5>This is heading 5</h5>\n",
    "<h6>This is heading 6</h6> \n",
    "```\n",
    "\n",
    "**Links**\n",
    "```html\n",
    "<a href=\"http://www.website.com\">Click to go to website.com</a>\n",
    "```\n",
    "\n",
    "**Images**\n",
    "```html\n",
    "<!-- Notice that the image tag has no closing tag and no content outside the opening tag -->\n",
    "<img src=\"smiley.gif\">\n",
    "```\n",
    "\n",
    "**Lists**\n",
    "```html\n",
    "<!-- Unordered (bulleted) list -->\n",
    "<ul>\n",
    "  <li>One Element</li>\n",
    "  <li>Another Element</li>\n",
    "</ul>\n",
    "\n",
    "<!-- Ordered (numbered) list -->\n",
    "<ol>\n",
    "  <li>First Ordered Element</li>\n",
    "  <li>Second Ordered Element</li>\n",
    "</ol>\n",
    "```\n",
    "\n",
    "**Tables**\n",
    "```html\n",
    "<table>\n",
    "  <!-- An HTML table is defined as a series of rows (<tr>) -->\n",
    "  <!-- The individual cell (<td>) contents are nested inside rows -->\n",
    "  \n",
    "  <!-- The <tr> tag is optional and is the parent of column headers (<th>) -->\n",
    "  <tr>\n",
    "    <th>First Header</th>\n",
    "    <th>Second Header</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Row 2, Col 1</td>\n",
    "    <td>Row 2, Col 2</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Row 3, Col 1</td>\n",
    "    <td>Row 3, Col 2</td>\n",
    "  </tr>\n",
    "</table>\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "more_tags = \"\"\"\n",
    "<html>\n",
    "<head>\n",
    "  <title>More HTML Tags</title>\n",
    "</head>\n",
    "<body>\n",
    "  <h1>This is heading 1</h1>\n",
    "  <h2>This is heading 2</h2>\n",
    "  <h3>This is heading 3</h3>\n",
    "  <h4>This is heading 4</h4>\n",
    "  <h5>This is heading 5</h5>\n",
    "  <h6>This is heading 6</h6>\n",
    "\n",
    "  <br>\n",
    "  \n",
    "  <a href=\"http://www.website.com\">Click to go to website.com</a>\n",
    "\n",
    "  <p><img src=\"../images/smiley.png\" alt=\"smiley face\"></p>\n",
    "\n",
    "  <ul>\n",
    "    <li>One Element</li>\n",
    "    <li>Another Element</li>\n",
    "  </ul>\n",
    "\n",
    "  <ol>\n",
    "    <li>First Ordered Element</li>\n",
    "    <li>Second Ordered Element</li>\n",
    "  </ol>\n",
    "\n",
    "  <table>\n",
    "    <!-- An HTML table is defined as a series of rows (<tr>) -->\n",
    "    <!-- The individual cell (<td>) contents are nested inside rows -->\n",
    "    <tr>\n",
    "      <!-- The <tr> tag defines a column headers -->\n",
    "      <th>First Header</th>\n",
    "      <th>Second Header</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>Row 2, Col 1</td>\n",
    "      <td>Row 2, Col 2</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "    <td>Row 3, Col 1</td>\n",
    "    <td>Row 3, Col 2</td>\n",
    "  </tr>\n",
    "  </table>\n",
    "</body>\n",
    "</html>\n",
    "\"\"\"\n",
    "\n",
    "HTML(more_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to know more about HTML, I recommend the excellent w3schools website: http://www.w3schools.com/html/html_intro.asp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Ok, back to web scraping\n",
    "\n",
    "Now we are all HTML experts. Great! We're almost ready to start parsing and analyzing a scraped web page. There's just one last item of business we need to discuss before we get started."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Viewing a page's source code\n",
    "\n",
    "In order to extract elements of interest from a webpage we need to know where they sit in the webpage's HTML tree.\n",
    "This means that you need to look at a webpage's HTML source code before you can even start scraping it. Not only that but, during your web scraping you will be switching back and forth between the actual scraping (we'll get there really soon, I promise!) and the webpage's source code.\n",
    "\n",
    "How do we view a page's source code then?\n",
    "\n",
    "* To view the **full page** source code:\n",
    "  1. Right-click anywhere on the webpage **that is not a link**\n",
    "  2. Click \"View Page Source\" (<kbd>CTRL</kbd>+<kbd>U</kbd>) in Firefox or Chrome, or \"Show page source\" (<kbd>&#8997;</kbd>+<kbd>&#8984;</kbd>+<kbd>U</kbd>) in Safari.\n",
    "    * In order to view the source code in Safari the Develop menu must be enabled first: Preferences > Advanced > Show Develop menu in menu bar\n",
    "    \n",
    "* To view the source code zoomed-in on **a single element** (and with better formatting!):\n",
    "  1. Right-click any element in the webpage.\n",
    "  2. Click \"Inspect Element\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Beautiful Soup, so rich and green, Waiting in a hot tureen!\n",
    "\n",
    "We made it! We are now ready to start scraping web pages. In order to do so we are going to use [`BeautifulSoup`](http://www.crummy.com/software/BeautifulSoup/bs4/doc/), a powerful python package to parse web pages you already scraped. Normally you would use `requests` (to GET the page) and then `BeautifulSoup` to analyse the web page. But to make life easier, and to avoid having upwards of 200 people scraping a webpage at once, we will use previously scraped webpages for the remainder of the lecture... You did take that personality quiz over the weekend like we suggested right?\n",
    "\n",
    "We will use the wikipedia page for a player from Germany's national football team as an example: https://en.wikipedia.org/wiki/Erik_Durm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Beautiful Soup version 4.x\n",
    "import bs4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by opening up the page and convert it to a \"soup\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We specify the encoding of the file here because Windows\n",
    "# has problems reading some characters in it.\n",
    "\n",
    "with open(\"../Data/erik_durm_wiki.html\", \"r\", encoding=\"utf-8\") as wiki_file:\n",
    "        soup = bs4.BeautifulSoup(wiki_file.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to use the `find` method to find the page's `<title>` tag and print it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "title = soup.find('title')   #finds the FIRST <title> tag \n",
    "print(title.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beautiful Soup converts HTML tags into its own `Tag` objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(type(title))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Tag` objects have several useful attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(title.text) # The text gives you the visible part of the tag\n",
    "print(title.name) # The type of tag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If a tag has any html attributes, they can be accessed in a very \"pythonic\" way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "h1 = soup.find(\"h1\")\n",
    "\n",
    "print(h1.attrs)\n",
    "print(h1[\"class\"])\n",
    "print(h1[\"id\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yep, just like a dictionary!\n",
    "\n",
    "Now, let's try to find ALL level 2 headers. To do that we use the `find_all` method instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "headers = soup.find_all('h2')\n",
    "\n",
    "print(headers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ugh, that's a mess, let's try printing each header individually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for header in headers:\n",
    "    print(header.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Much better! We can also find all the other pages that this webpage links to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "links = soup.find_all('a')\n",
    "\n",
    "for link in links[:20]:  # Showing just the first 20 links for brevity\n",
    "    # href represents the target of the link\n",
    "    # Where the link actually goes to!\n",
    "    print(link.get('href'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also search for elements with specific attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Gets a specific element, in this case a section header with the attribute \"id\"\n",
    "soup.find(id=\"Early_career\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Here's another way to search for all valid links:\n",
    "# Just search for all elements with an href attribute!\n",
    "all_links = soup.find_all(href=True)\n",
    "print(len(all_links))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Gets all inline citations! They are <sup> elements with the class \"reference\"\n",
    "soup.find_all(\"sup\", class_=\"reference\")[10:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we must use \"class_\" instead of \"class\" to avoid conflicts with python's built-in keyword. Remember the [Data Types](../Python-Basics/Data-Types.ipynb) lecture?\n",
    "\n",
    "More generally, you can pass a dictionary of attributes to search for:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Find all tags with class=mw-headline and an id attribute (regardless of value)\n",
    "soup.find_all(attrs={\"class\": \"mw-headline\", \"id\": True})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra! Some more HTML\n",
    "\n",
    "`class` and `id` are special HTML attributes that allow for a rich connection between HTML and CSS and Javascript. Feel free to google the subject. We won't go into the details here. Just know that:\n",
    "\n",
    "* The `id` attribute is used to uniquely identify a tag. This means that all `id` attributes should have different values in a webpage.\n",
    "\n",
    "* The `class` attribute is used to identify tags which share certain properties. A tag can have more than one `class` value:\n",
    "```html\n",
    "   <!-- Separate extra classes by a space -->\n",
    "   <tag class=\"first_class second_class\">...</tag>\n",
    "```\n",
    "\n",
    "In the above example, notice that all reference elements (`<sup>` tags) have the same `class` value but different `id` values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Navigating the HTML tree with BeautifulSoup\n",
    "\n",
    "Besides being able to search elements anywhere on the whole html tree, beautiful soup also allows you to navigate the tree in any direction.\n",
    "\n",
    "Let's try to get at the first paragraph (`<p>`) in the `Club career` section starting from the section's title tag.\n",
    "\n",
    "Here's the relevant HTML snippet:\n",
    "\n",
    "```html\n",
    "    <h2>\n",
    "      <span class=\"mw-headline\" id=\"Club_career\">Club career</span>\n",
    "      <span class=\"mw-editsection\">\n",
    "        <span class=\"mw-editsection-bracket\">[</span>\n",
    "        <a href=\"/w/index.php?title=Erik_Durm&amp;action=edit&amp;section=1\" title=\"Edit section: Club career\">edit</a>\n",
    "        <span class=\"mw-editsection-bracket\">]</span>\n",
    "      </span>\n",
    "    </h2>\n",
    "    <h3>\n",
    "      <span class=\"mw-headline\" id=\"Early_career\">Early career</span>\n",
    "      <span class=\"mw-editsection\">\n",
    "        <span class=\"mw-editsection-bracket\">[</span>\n",
    "        <a href=\"/w/index.php?title=Erik_Durm&amp;action=edit&amp;section=2\" title=\"Edit section: Early career\">edit</a>\n",
    "        <span class=\"mw-editsection-bracket\">]</span>\n",
    "      </span>\n",
    "    </h3>\n",
    "    <p>Durm began his club career in 1998 at the academy of SG Rieschweiler....</p>\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "section_headline = soup.find(id=\"Club_career\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the snippet above we don't expect to have anything inside this tag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "list(section_headline.contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correct! The `contents` attribute lets us access everything that is inside a given tag. In this case we find only the visible text of the tag, as expected.\n",
    "\n",
    "So we need to go up one level (to the `<h2>` tag), then go to its second sibling (first `<h3>` then `<p>`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "parent_h2 = section_headline.parent\n",
    "\n",
    "parent_h2.name == \"h2\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We got the parent! What's inside it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "parent_h2.contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's the code that lets you edit a section!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a convenience, you can access the first children of a given parent tag using its name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "parent_h2.contents[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "parent_h2.contents[1].span"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cool, huh?\n",
    "\n",
    "Now, from the earlier snippet we can see that our target, the first `<p>` in the section, is the next sibling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "parent_h2.next_sibling.next_sibling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmmm, not there yet. This is because some of the siblings in the soup are not actual HTML elements but simply empty lines due to potential parsing issues:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "parent_h2.next_sibling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is something we must always be mindful about. Web scraping can, and very frequently will be messy and will involve trial-and-error.... But we are not ones to be defeated by a puny new line are we?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "parent_h2.next_sibling.next_sibling.next_sibling.next_sibling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sucess!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That was the brute force way. It works most of the time. But in this case there is a better option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "parent_h2.find_next_sibling(\"p\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Much simpler!\n",
    "\n",
    "Similarly you have find_previous_sibling, find_next_children, find_previous_children, and some others.\n",
    "\n",
    "The [Beautiful Soup documentation](http://www.crummy.com/software/BeautifulSoup/bs4/doc/) has a comprehensive list of all these methods. There is no need to memorize all of them. It's more important to realize that, as with any programming language, there is more than one way to get any element of the html tree. The trick is to *pick a good starting point* from where to start the scraping."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scraping images from a webpage\n",
    "\n",
    "You can also use Beautiful Soup to get the source of an image from a webpage. It works just the same as for text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Some modules that will allows us to display images and other media in the notebook itself\n",
    "from IPython.display import display, Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for image in soup.find_all('img'):\n",
    "    print(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can pinpoint a specific image and get its attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "images = soup.find_all('img')\n",
    "img0 = images[0]\n",
    "print(img0.attrs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can display the image using its `src` attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "display(Image(url=img0['src']))\n",
    "\n",
    "display(Image(url=images[1]['src']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise: scraping results from your Personality table\n",
    "\n",
    "For this exercise you will use your results from the personality quiz at [HEXACO](http://hexaco.org/hexaco-online). You did take the quiz right? :)\n",
    "\n",
    "Save the page with the quiz results to: `<path to the bootcamp directory>/Data/my_hexaco.html`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(\"../Data/my_hexaco.html\", \"r\", encoding=\"utf-8\") as hexaco_file:\n",
    "        soup = bs4.BeautifulSoup(hexaco_file.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 - Find the `<table>` element, that contains your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "table = soup.find() # your search terms inside the `find` method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 -  Find all the scale names using the `table` variable from above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Find all table rows, skipping the first two which don't matter\n",
    "for tag in table.find_all(\"tr\")[2:]:\n",
    "    cells = tag.find_all(\"td\")\n",
    "    \n",
    "    # Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3: Now get both the scale names and your own scores associated with each scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Find all table rows, skipping the first two which don't matter\n",
    "for tag in table.find_all(\"tr\")[2:]:\n",
    "    cells = tag.find_all(\"td\")\n",
    "\n",
    "    # Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from IPython.core.display import HTML\n",
    "\n",
    "\n",
    "def css_styling():\n",
    "    styles = open(\"../styles/custom.css\", \"r\").read()\n",
    "    return HTML(styles)\n",
    "css_styling()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

{
 "metadata": {
  "name": "",
  "signature": "sha256:44390e028dc02a1e42a03b8b686365d45dafd2ba681f62b5c0c10ef5f4c28cf5"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# An Introduction to Web Scraping\n",
      "\n",
      "How you can use python to extract or scrape any type of content from web pages.\n",
      "In this tutorial we will learn how to extract simple text elements, images, and tables from different web pages.\n",
      "\n",
      "New 3rd party packages we will use:\n",
      "\n",
      "* **requests**: http://docs.python-requests.org/en/latest/user/quickstart/\n",
      "  * The requests package can crawl (load) webpages and download (scrape) their contents\n",
      "* **Beautiful Soup**: http://www.crummy.com/software/BeautifulSoup/bs4/doc/\n",
      "  * The Beautiful Soup package can transform scraped web content into an object that can be parsed and analyzed"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# regex's is short for Regular Expressions.\n",
      "# Regex's are strings that you can use to perform almost any kind of\n",
      "# pattern matching.\n",
      "# The re package contains the python functions used for regex pattern\n",
      "# matching.\n",
      "import re\n",
      "\n",
      "import requests\n",
      "\n",
      "# Beautiful Soup version 4.x\n",
      "import bs4\n",
      "\n",
      "# ipython notebook-specific library to display images and other media inline\n",
      "from IPython.display import display, Image\n",
      "\n",
      "# ipython notebook-specific library to render HTML code\n",
      "from IPython.display import HTML"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Making a request"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "response = requests.get(\"http://bootcamp-form.herokuapp.com/\") # Returns a Reponse object\n",
      "\n",
      "print(response) # Response status code\n",
      "print(response.status_code)\n",
      "print(response.url)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Most common HTTP status codes:\n",
      "* 200, **OK**. Request was successful\n",
      "* 303, **See Other**. Page redirected to another URL. Your web browser automatically fetches the new URL but web crawlers do not usually do this unless you specify it.\n",
      "* 401 **Unauthorized**. The URL requires authentication (e.g. password) which was not provided or was incorrect.\n",
      "* 404, **Not Found**. The URL does not exist\n",
      "* 500 **Internal Server Error**. The server is having _unexpected_ problems and the web page is down.\n",
      "* 503 **Service Unavailable**. The web page is down, likely for server maintenance.\n",
      "\n",
      "More codes: http://en.wikipedia.org/wiki/List_of_HTTP_status_codes"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# The raw html content, i.e., the web page's source code\n",
      "# is accessible from the Response.text variable\n",
      "print(response.text)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "---\n",
      "## Detour: A (very brief) intro to HTML"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "HTML is a markup language for describing web documents. It stands for **H**yper **T**ext **M**arkup **L**anguage. HTML, together with CSS (**C**ascading **S**tyle **S**heets for _styling_ web documents) and Javascript (for _animating_ web documents), is the language that is used to construct web pages.\n",
      "\n",
      "HTML documents are built using a series of HTML _tags_. Each tag describes a different type of content. Web pages are built by putting together different tags.\n",
      "\n",
      "General HTML tag structure:\n",
      "\n",
      "```html\n",
      "<tagname tag_attribute1=\"attribute1value1 attribute1value2\" tag_attribute2=\"attribute2value1\">tag contents</tagname>\n",
      "```\n",
      "* Tags (usually) have both a start (or opening) tag, <tagname> and an end (or closing) tag, </tagname>\n",
      "* Tags can also have attributes which are declared _inside_ the opening tag.\n",
      "* The actual tag _content_ goes inbetween the opening and closing tags."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Tags can be contained (nested) inside other tags, which defines relationships between them:\n",
      "\n",
      "```html\n",
      "<parent>\n",
      "  <brother></brother>\n",
      "  <sister>\n",
      "    <grandson></grandson>\n",
      "  </sister>\n",
      "</parent>\n",
      "```\n",
      "\n",
      "* `<parent>` is the _parent_ tag of `<brother>` and `<sister>`\n",
      "* `<brother>` and `<sister>` are the _children_ or _direct descendant_ tags of `<parent>`\n",
      "* `<brother>`, `<sister>`, and `<grandson>` are the _descendant_ tags of `<parent>`\n",
      "* `<brother>` and `<sister>` are _sibling_ tags"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Here's a very simple web document:\n",
      "\n",
      "```html\n",
      "<!DOCTYPE html>\n",
      "<html>\n",
      "  <head>\n",
      "    <title>Page Title</title> \n",
      "  </head>\n",
      "\n",
      "  <body>\n",
      "    <h1>My First Heading</h1>\n",
      "    <p>My first paragraph.</p>\n",
      "  </body>\n",
      "</html> \n",
      "```\n",
      "\n",
      "When you access any URL, your browser (Chrome, Firefox, Safari, IE, etc.) is actually reading a document such this one and using the tags in the document to decide how to render the page for you."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "first_html = \"\"\"\n",
      "<!DOCTYPE html>\n",
      "<html>\n",
      "  <head>\n",
      "    <title>Page Title</title>\n",
      "  </head>\n",
      "  \n",
      "  <body>\n",
      "    <h1>My First Heading</h1>\n",
      "    <p>My first paragraph.</p>\n",
      "  </body>\n",
      "\n",
      "</html> \n",
      "\"\"\"\n",
      "HTML(first_html)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Let's look at what the different tags mean:\n",
      "\n",
      "```html\n",
      "<!-- This is how you write a comment in HTML. Comments will not appear in the browser -->\n",
      "\n",
      "<!-- This line simply identifies the document type to be HTML-->\n",
      "<!DOCTYPE html>\n",
      "<!-- Content between <html> and </html> tags define everything about the document-->\n",
      "<html>\n",
      "  <!-- Tags inside the <head> provide information about the document -->\n",
      "  <head>\n",
      "    <!-- Like the <title> tag which provides a title that appears in the browser's title and tab bars -->\n",
      "    <title>Page Title</title>\n",
      "  </head>\n",
      "  \n",
      "  <!-- Anything inside the <body> tags describes visible page content -->\n",
      "  <body>\n",
      "    <!-- The <h1> defines a header. The number defines the size of the header. -->\n",
      "    <!-- There are 6 levels of headers: <h1> to <h6> -->\n",
      "    <!-- The higher the number, the lower the font used to display it. -->\n",
      "    <h1>My First Heading</h1>\n",
      "    <!-- The <p> represents a paragraph.-->\n",
      "    <p>My first paragraph.</p>\n",
      "  </body>\n",
      "</html>\n",
      "```"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Other important HTML tags"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Diferent levels of headers**\n",
      "\n",
      "```html\n",
      "<h1>This is heading 1</h1>\n",
      "<h2>This is heading 2</h2>\n",
      "<h3>This is heading 3</h3>\n",
      "<h4>This is heading 4</h4>\n",
      "<h5>This is heading 5</h5>\n",
      "<h6>This is heading 6</h6> \n",
      "```\n",
      "\n",
      "**Links**\n",
      "```html\n",
      "<a href=\"http://www.website.com\">Click to go to website.com</a>\n",
      "```\n",
      "\n",
      "**Images**\n",
      "```html\n",
      "<!-- Notice that the image tag has no closing tag and no content outside the opening tag -->\n",
      "<img src=\"smiley.gif\">\n",
      "```\n",
      "\n",
      "**Lists**\n",
      "```html\n",
      "<ul>\n",
      "  <li>One Element</li>\n",
      "  <li>Another Element</li>\n",
      "</ul>\n",
      "\n",
      "<ol>\n",
      "  <li>First Ordered Element</li>\n",
      "  <li>Second Ordered Element</li>\n",
      "</ol>\n",
      "```\n",
      "\n",
      "**Tables**\n",
      "```html\n",
      "<table>\n",
      "  <!-- An HTML table is defined as a series of rows (<tr>) -->\n",
      "  <!-- The individual cell (<td>) contents are nested inside rows -->\n",
      "  <tr>\n",
      "    <!-- The <tr> tag defines column headers -->\n",
      "    <th>First Header</th>\n",
      "    <th>Second Header</th>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>Row 2, Col 1</td>\n",
      "    <td>Row 2, Col 2</td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>Row 3, Col 1</td>\n",
      "    <td>Row 3, Col 2</td>\n",
      "  </tr>\n",
      "</table>\n",
      "```"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "more_tags = \"\"\"\n",
      "<html>\n",
      "<head>\n",
      "  <title>More HTML Tags</title>\n",
      "</head>\n",
      "<body>\n",
      "  <h1>This is heading 1</h1>\n",
      "  <h2>This is heading 2</h2>\n",
      "  <h3>This is heading 3</h3>\n",
      "  <h4>This is heading 4</h4>\n",
      "  <h5>This is heading 5</h5>\n",
      "  <h6>This is heading 6</h6>\n",
      "\n",
      "  <br>\n",
      "  \n",
      "  <a href=\"http://www.website.com\">Click to go to website.com</a>\n",
      "\n",
      "  <p><img src=\"smiley.gif\"></p>\n",
      "\n",
      "  <ul>\n",
      "    <li>One Element</li>\n",
      "    <li>Another Element</li>\n",
      "  </ul>\n",
      "\n",
      "  <ol>\n",
      "    <li>First Ordered Element</li>\n",
      "    <li>Second Ordered Element</li>\n",
      "  </ol>\n",
      "\n",
      "  <table>\n",
      "    <!-- An HTML table is defined as a series of rows (<tr>) -->\n",
      "    <!-- The individual cell (<td>) contents are nested inside rows -->\n",
      "    <tr>\n",
      "      <!-- The <tr> tag defines a column headers -->\n",
      "      <th>First Header</th>\n",
      "      <th>Second Header</th>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <td>Row 2, Col 1</td>\n",
      "      <td>Row 2, Col 2</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "    <td>Row 3, Col 1</td>\n",
      "    <td>Row 3, Col 2</td>\n",
      "  </tr>\n",
      "  </table>\n",
      "</body>\n",
      "</html>\n",
      "\"\"\"\n",
      "\n",
      "HTML(more_tags)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "For more about HTML: http://www.w3schools.com/html/html_intro.asp"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "---\n",
      "### Back to web scrapping"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "response = requests.get(\"http://bootcamp-form.herokuapp.com/\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Selecting the text from the Bootcamp's front page"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# First we turn the document into a \"soup\"\n",
      "soup = bs4.BeautifulSoup(response.text)\n",
      "\n",
      "# The text from the front page is declared as headers of different levels\n",
      "bootcamp_text = soup.find_all(\"h1\")        # finds all <h1> tags in the document\n",
      "\n",
      "# Remaining pieces of text\n",
      "bootcamp_text.extend( soup.find_all(\"h3\") )\n",
      "bootcamp_text.extend( soup.find_all(\"h4\") )\n",
      "\n",
      "for header in bootcamp_text:\n",
      "    print(header.text)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Beautiful Soup converts HTML tags into its own \"Tag\" objects\n",
      "print(type(bootcamp_text[0]))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# These objects have several useful attributes\n",
      "print(bootcamp_text[0].text)\n",
      "print(bootcamp_text[0].name)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Selecting the logos from the Bootcamp's front page"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "logos = soup.find_all(\"img\")\n",
      "print(logos)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# The html tag's attributes are also stored\n",
      "print(logos[0].attrs)\n",
      "print(logos[0][\"class\"])\n",
      "print(logos[0][\"src\"])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# You can also use Beautiful Soup to find one specific element\n",
      "# You can also specify attributes to make the search more precise\n",
      "nico_logo = soup.find(\"img\", class_=\"nico_logo\")\n",
      "print(nico_logo)\n",
      "\n",
      "# Or equivalently\n",
      "# print(soup.find(\"img\", alt=\"NICO\"))\n",
      "# print(soup.find(\"img\", src=\"nico_logo.gif\"))\n",
      "\n",
      "# The \"src\" attribute represents a relative path of the image from the current URL\n",
      "# To get the actual image we must prepend the web page's URL\n",
      "display( Image(url=response.url + \"/\" + nico_logo[\"src\"]) )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Selecting elements by their position in a web document (or page)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# let's look at the Bootcamp page again\n",
      "print(soup.prettify())     # prettify() adds indentation to the HTML"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Notice how the images are nested inside `<a>` tags which in turn are nested inside `<li>` tags, nested inside `<ul>`:\n",
      "\n",
      "```html\n",
      "<ul class=\"nav navbar-nav navbar-right\">\n",
      "  <li class=\"active\">\n",
      "    <a class=\"menu-button\" href=\"http://amaral-lab.org/\">\n",
      "      <img alt=\"Amaral Lab\" class=\"amaral_logo\" src=\"amaral-logo-white.png\" style=\"height:30px\"/>\n",
      "        Amaral Lab\n",
      "    </a>\n",
      "  </li>\n",
      "  <li class=\"active\">\n",
      "    <a class=\"menu-button\" href=\"http://www.nico.northwestern.edu/index.html\">\n",
      "      <img alt=\"NICO\" class=\"nico_logo\" src=\"nico_logo.gif\"/>\n",
      "    </a>\n",
      "  </li>\n",
      "</ul>\n",
      "```"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "amaral_logo = soup.find(\"img\", class_=\"amaral_logo\")\n",
      "\n",
      "# You can navigate from one Tag to any of its relatives\n",
      "print(amaral_logo.parent.prettify())\n",
      "\n",
      "print()\n",
      "\n",
      "print(amaral_logo.parent.parent.parent.prettify())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# You can even navigate using tag names\n",
      "amaral_logo.parent.parent.parent.li.next_sibling"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# You can even navigate using tag names\n",
      "nico_li = amaral_logo.parent.parent.parent.li.next_sibling.next_sibling\n",
      "\n",
      "print(nico_li.prettify())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now we can finally extract the other logo"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nico_logo = nico_li.a.img\n",
      "\n",
      "display(Image(url=response.url + \"/\" + nico_logo[\"src\"]))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Scraping Exercises"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Soccer Premier League [scores](http://en.wikipedia.org/wiki/1992%E2%80%9393_FA_Premier_League#League_table)\n",
      "\n",
      "Write a function `get_league_table` that returns the html `<table>...</table>` element with the final league scores for a given year. Then use the provided `html_table_to_df` to convert the table to a pandas DataFrame."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def html_table_to_list(html_table):\n",
      "    \"\"\"\n",
      "    Takes an html <table>...</table> BeautifulSoup element\n",
      "    and converts it to an equivalent python list.\n",
      "    \"\"\"\n",
      "    table_rows = html_table.find_all(\"tr\")\n",
      "    \n",
      "    # If the html table has headers then we store this \n",
      "    # fact to properly add the DataFrame labels\n",
      "    has_headers = bool(table_rows[0].find_all(\"th\"))\n",
      "    \n",
      "    table_list = []\n",
      "    for row in table_rows:\n",
      "        table_list.append(\n",
      "            # Because table cells can have other tags inside them,\n",
      "            # it is easier to get all the text inside the row\n",
      "            # and manually remove any newline characters.\n",
      "            # Note that the newlines are from the html code itself.\n",
      "            \n",
      "            # \"\\xa0\" is a whitespace character in the Latin-1 encoding\n",
      "            # which Beautiful Soup encodes incorrectly using utf-8\n",
      "            row.text.replace(\"\\xa0\", \" \").strip(\"\\n\").split(\"\\n\")\n",
      "        )\n",
      "    \n",
      "    return table_list"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_league_table(url):\n",
      "    \"\"\"\n",
      "    Searchers `url` for the html table with the league results\n",
      "    and returns it as a Beautiful Soup Tag object\n",
      "    \"\"\"\n",
      "    # Get the text from the url\n",
      "\n",
      "    # Turn it into a \"soup\"\n",
      "\n",
      "    \n",
      "    # Hint: Check the source code from wikipedia.\n",
      "    # Does the league scores element have any\n",
      "    # attributes we can use to find it?\n",
      "    # What about the parent of the league scores element??\n",
      "    \n",
      "    \n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Test your code here\n",
      "\n",
      "# 1992 Premier league scores\n",
      "root_url = \"http://en.wikipedia.org/wiki/1992%E2%80%9393_FA_Premier_League\"\n",
      "\n",
      "html_table = get_league_table(root_url)\n",
      "html_table_to_df(html_table)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Scraping song lyrics from [AZLyrics](http://www.azlyrics.com)\n",
      "\n",
      "Create a function `get_song_lyrics` that scrape the lyrics of a song from its page, given the song's url.\n",
      "You can use the provided `get_artist_songs` to get a list of song lyrics and to get inspiration for how to write your scraper."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "root_url = \"http://www.azlyrics.com\"\n",
      "\n",
      "def get_artist_songs(artist_name):\n",
      "    \"\"\"\n",
      "    Given an artist's name, crawls AZLyrics.com for that artist's songs.\n",
      "    Returns a list of links to each song's lyrics' page.\n",
      "    \"\"\"\n",
      "    # This line removes any strange characters (e.g. @#$%^&*, etc)\n",
      "    # and white spaces from the artist's name and converts it to\n",
      "    # lower case\n",
      "    artist_name = re.sub(\"[\\s\\W]+\", \"\", artist_name).lower()\n",
      "    \n",
      "    # artist page url is of the form:\n",
      "    # http://www.azlyrics.com/[Artist Initial]/[Artist Name].html\n",
      "    artist_url = \"/\" + artist_name[0] + \"/\" + artist_name + \".html\"\n",
      "    \n",
      "    response = requests.get(root_url + artist_url)\n",
      "    soup = bs4.BeautifulSoup(response.text)\n",
      "    \n",
      "    songs = []\n",
      "    song_elements = soup.find(\"div\", id=\"listAlbum\")\n",
      "    for song_link in song_elements.find_all(\"a\", target=\"_blank\"):\n",
      "        songs.append(song_link.attrs.get(\"href\")[3:])\n",
      "    \n",
      "    return(songs)\n",
      "\n",
      "\n",
      "def get_song_lyrics(song_url):\n",
      "    \"\"\"\n",
      "    Given a song's url, crawl's AZLyrics for that song's lyric\n",
      "    and returns it as a tuple of strings:\n",
      "    (song title, song lyrics)\n",
      "    \"\"\"\n",
      "    pass"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Test your code here\n",
      "\n",
      "# Pick an artist\n",
      "artist_name = \"\"\n",
      "artist_songs = get_artist_songs(artist_name)\n",
      "\n",
      "#lyrics = get_song_lyrics(artist_songs[])\n",
      "\n",
      "# print(artist_name + \"\\n\")\n",
      "# print(lyrics[0])\n",
      "# print(\"=\"*len(lyrics[0]))\n",
      "# print(lyrics[1])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}
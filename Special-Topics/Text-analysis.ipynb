{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Text analysis\n",
    "Whether it's extracting numerical data from text, or dealing with text directly, the ability to manipulate text in the form of strings is essential for any number of data science projects. \n",
    "\n",
    "Here, we're going to take a walk over to the humanities and see if we can learn anything new about our favorite author... William Shakespeare (if we all had to learn it, so should a computer, right?). We might ask...\n",
    "\n",
    "1. Should \"Othello\" really be called \"Iago\"?\n",
    "\n",
    "2. Can a computer learn the difference between a comedy and a tragedy?\n",
    "\n",
    "3. Who is the most verbose Shakespearean character?\n",
    "\n",
    "4. Who has the largest vocabulary? \n",
    "\n",
    "5. Did the complexity of Shakespeare's vocabulary change over time?\n",
    "\n",
    "6. Which is Shakespeare's most feminist play?\n",
    "\n",
    "We could think of any number of quantitative questions to pursue, each requiring slightly different skills and analytical depth. Let's start with something easy and build our way up. By the end you should have the skills to answer some of the above questions. \n",
    "\n",
    "#The Data\n",
    "Where are we going to get data? [Project Gutenberg](http://www.gutenberg.org) has 1000's of different post-copyright books freely available in the form of easy-to-use `.txt` files. Luckily for us, this includes the complete works of William Shakespeare which we've pre-downloaded for you.\n",
    "\n",
    "First things first, **ALWAYS LOOK AT YOUR DATA**. Now is the time to open `'../Data/Shakespeare.txt'` and get a sense for the file formatting. (You can do this quickly by clicking: [Shapespeare.txt](../Data/Shakespeare.txt)).\n",
    "\n",
    "1. How are different plays separated from one another?\n",
    "2. How is dialogue formatted?\n",
    "3. What extraneous information might we want to ignore?\n",
    "4. How \"well behaved\" is our dataset? (i.e. is the formatting general or unique for different plays?)\n",
    "\n",
    "These are all important questions that we can only infer from qualitative visual exploration. \n",
    "\n",
    "#Text parsing review\n",
    "Before we dive into this large file, let's do a brief refresher on some text parsing basics which will give us an excuse to spoil Hamlet for you. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spoiler_alert = [\"O, I die, Horatio!\\n\",\n",
    "    \"The potent poison quite o'ercrows my spirit.\\n\",\n",
    "    \"I cannot live to hear the news from England,\\n\",\n",
    "    \"     But I do prophesy th' election lights\\n\",\n",
    "    \"On Fortinbras. He has my dying voice.\\n\",\n",
    "    \"So tell him, with th' occurrents, more and less,\\n\",\n",
    "    \"\\n\",             \n",
    "    \"Which have solicited- the rest is silence.             Dies.\\n\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we didn't know what was in `spoiler_alert`, we would have to iterate through the lines to see what the data looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for line in spoiler_alert:\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Removing extraneous characters\n",
    "Remember, `\\n` is a new line character so it isn't actually displayed. It is still there, the `print` function just interprets it to say `new line` which is why we have double-spacing going on here (one line is added during the `for` loop, another is added by each `\\n`).\n",
    "\n",
    "We can get rid of the extra spaces easily enough, though:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for line in spoiler_alert:\n",
    "    print(line.strip('\\n'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the `\\n` really is gone, and our text isn't double spaced. Remember, we're not actually changing `spoiler_alert`. We're only temporarily removing the `\\n` as we print each line. Thus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for line in spoiler_alert:\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `\\n` characters are still there! That's okay, I just wanted to remind you of this crucial aspect of `for` loops.\n",
    "\n",
    "So `str.strip('\\n')` removes the `\\n` characters, but it still leaves a weird spacing before \"But I do prophesy...\". \n",
    "\n",
    "Instead, we could just say `str.strip()` and by default it will remove _all_ white space, which includes `\\t` (tab) `\\n` (new line) and '' (spaces) from both the right _and_ left ends. Note that `str.lstrip()` and `str.rstrip()` only remove characters from one end at a time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for line in spoiler_alert:\n",
    "    print(line.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that `strip()` doesn't remove anything from the middle of a line, so there is still a ton of space before 'Dies'. The `strip()` method will only remove characters from the ends of a string. This isn't a problem for us, but is important to remember.\n",
    "\n",
    "##Getting line (index) numbers\n",
    "Another handy function is `enumerate`. Suppose I wanted to know the line numbers: it's pretty trivial with this short list but we won't always work with short lists. For longer text, `enumerate` is a lifesaver. Let's see it in action:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for line in enumerate(spoiler_alert):\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`enumerate` took our list of strings named `spoiler_alert` and created a list of tuples! The **first** item in each tuple is the index within the original list (`spoiler_alert`), and the **second** item is the actual string. This will come in handy later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Searching in text\n",
    "Let's do a little searching:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for line in spoiler_alert:\n",
    "    if 'The' in line:\n",
    "        print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why aren't line 2 (\"I cannot live...\") or 7 (\"Which have solicited...\") printed?\n",
    "\n",
    "**Capitalization matters!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for line in spoiler_alert:\n",
    "    if 'the' in line:\n",
    "        print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we got lines 2 and 7, but we missed line 1!\n",
    "\n",
    "Maybe we don't care about capitalization, and just want to know whether 'the' appears anywhere within the line. We'll have to standardize our search by converting each line to lowercase before searching it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for line in spoiler_alert:\n",
    "    if 'the' in line.lower():\n",
    "        print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same works for uppercase:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for line in spoiler_alert:\n",
    "    if 'the' in line.upper():\n",
    "        print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We didn't find anything here. Why not? \n",
    "\n",
    "We temporarily made the lines uppercase, so lowercase `the` never appears in any of them! We should have said:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for line in spoiler_alert:\n",
    "    if 'THE' in line.upper():\n",
    "        print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is this the only way to find something in a line? Of course not! Programming wouldn't be fun if there weren't 1000 ways to do the same thing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for line in spoiler_alert:\n",
    "    if line.find('the') != -1:\n",
    "        print(line.strip(), line.find('the'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not only does `find` tell us whether the text appears in the line, but also exactly where in the line the text appears (indexing from 0). If it doesn't find our search query it will return -1. These methods can also be combined in linear chains:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for line in spoiler_alert:\n",
    "    if line.lower().find('the') != -1: #Now we're lowercasing the line first before searching\n",
    "        print(line.strip(), line.lower().find('the'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`index` works similarly to `find`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for line in spoiler_alert:\n",
    "    if line.index('the') != -1:\n",
    "        print(line.strip(), line.find('the'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Except `index` gave us a `ValueError`. Why?\n",
    "\n",
    "When using `index`, if the string isn't found it raises an error rather than returning `-1`. We need to try something slightly different. Remember our old friend try/except?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for line in spoiler_alert:\n",
    "    try:\n",
    "        print(line.strip(), line.lower().index('the'))\n",
    "    except ValueError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've now learned a few different ways to search for substrings inside of strings. Capitalization really matters for all of them, and there are minor differences between methods that you need to keep in mind. \n",
    "\n",
    "We also learned that `enumerate` makes it easy to find the line number in which substrings occurred:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for line in enumerate(spoiler_alert):\n",
    "    if 'the' in line[1].lower(): #We have to look in the string, which is index one in the enumerate tuple\n",
    "        print('Line number: ', line[0], '**** Line: ', line[1])#And only print the line number line[1] is the full line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now know that 'the' appears on lines 1, 2, and 7. This might be useful at some point. For instance, what if we only want the lines between the first and last occurences of 'my'? \n",
    "\n",
    "**Exercise:** Use your favorite method to find lines containing the word 'my'. Next, append all lines _between_ (and including!) the lines containing the substring 'my' to their own list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lines_of_interest = []\n",
    "\n",
    "###Place your code here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#Splitting strings\n",
    "Let's do a refresher on splitting up strings. Maybe we just want a list of the words in each line rather than working with the entire line as a string:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for line in spoiler_alert:\n",
    "        print(line.split(','))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we turned each line into a list of clauses separated by commas. In lines without commas, the line became a list with a single element. In lines with commas, the string was split into separate strings based on the position of those commas (notice that the commas themselves are gone!).\n",
    "\n",
    "We could also split our lines based on spaces to isolate individual words (kind of):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for line in spoiler_alert:\n",
    "        print(line.split(' '))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I said _kind of_ because while it looks like most of these are single words, it's not perfect. The last word in each line still has that pesky '`\\n`', so let's combine commands to get rid of it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for line in spoiler_alert:\n",
    "        print(line.strip().split(' '))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The operations were performed in order. First we stripped white space off the left and right sides of the string. Then, we split the resultant string into a list based on spaces. Now we have a list of words for each line that looks slightly better than before (we still have errors, but we'll come back to that), but what if we wanted a list of words for the entire text rather than for each line?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "total_list = []\n",
    "for line in spoiler_alert:\n",
    "    line_as_list = line.strip().split(' ')\n",
    "    for word in line_as_list:\n",
    "        total_list.append(word)\n",
    "print(total_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This isn't so bad, but there are still some weird things in here that we probably don't want, like all of those empty strings that precede 'Dies' or any of the punctuation.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "total_list = []\n",
    "for line in spoiler_alert:\n",
    "    line_as_list = line.strip().split(' ')\n",
    "    for word in line_as_list:\n",
    "        total_list.append(word.rstrip('!'))\n",
    "print(total_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we're stripping (from the right side only) the exclamation marks. We may also want to strip the periods, colons, semi-colons, hyphens and question marks (or anything else). We can just lump all of these into `strip` and run `strip` for each word. If it doesn't find anything, it won't do anything. If it finds a question mark, it will remove it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "total_list = []\n",
    "for line in spoiler_alert:\n",
    "    line_as_list = line.strip().split(' ')\n",
    "    for word in line_as_list:\n",
    "        total_list.append(word.rstrip('!?.-;:'))\n",
    "print(total_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will still have apostrophes, but maybe we want to keep them. What about hyphenated words? Our current practice would keep strings like 'well-known' as one long word. Perhaps we are okay with that, or perhaps not. \n",
    "\n",
    "Let's wrap this up:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "total_list = []\n",
    "for line in spoiler_alert:\n",
    "    line_as_list = line.strip().split(' ')\n",
    "    for word in line_as_list:\n",
    "        if len(word) > 0:#This will make sure the string has something in it\n",
    "            total_list.append(word.rstrip('!?.,-;:').lower())\n",
    "print(total_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Everything is lowercase so  'The' and 'the' will be recognized as the same word, and we removed both punctuation and those pesky spaces/empty strings. Finally, we can get word counts, for which we'll rely on Counter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "Counter(total_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Back to Shakespeare.txt\n",
    "\n",
    "We've now created a dictionary of all the word counts in our sample text. Of course, we don't care about a tiny sample. Our real text is gigantic and contains a lot of stuff we don't need. Let's get serious and move on to some big(-ger) data. We need to start by reading in the file using python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "complete_works = open('../Data/Shakespeare.txt').readlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the next few tasks, I'm only interested  in 'Othello'. Look at where Othello begins in the text: how are we going to extract Othello and _only_ Othello from this large list of lines? How do _we_ know when Othello begins and ends?\n",
    "\n",
    "**Exercise:** Iterate through `complete_works` and add only the lines relevant to 'Othello' to the new list `othello_lines` (hint: there might be a string that differentiates Othello from other plays. And there might be another string that signifies the end of a play. How can you use search to find those lines and get the ones you want?)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "othello_lines = []\n",
    "###Place your code here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before moving on, **always** make sure you really have what you _think_ you have. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(othello_lines[0:20])\n",
    "print('**************')\n",
    "print(othello_lines[-20:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Dialogue\n",
    "We should all have a line-by-line reading of Othello. Now what? Your choice here is going to depend on what you want to analyze! I'm particularly interested in how many total and _unique_ words Othello speaks. With that information, I could apply similar analyses to see which character speaks the most and who has the biggest vocabulary. \n",
    "\n",
    "Since we only care about Othello, it may not be worth our time to extract the character list. We'll have to do that if we want to compare vocabulary between characters, but for now let's just worry about Othello. The fact that Othello is capitalized when he speaks makes things nice and easy for us (aside: his name _probably_ isn't capialized when he is referred to in dialogue from other characters. Can we be sure? No. As a rough approximation? Sure).\n",
    "\n",
    "```\n",
    "\"  CHARACTER. blahblahblah\n",
    "     blahblahblah\"\n",
    "```\n",
    "\n",
    "Two things jump out at me. How about you?\n",
    "\n",
    "1. Before a character speaks there are always (usually?) *2* spaces, followed by the character in all capital letters, followed by a period. \n",
    "2. It also looks like some speeches are longer than a single line, but those speeches have 4 spaces(!). We'll make note of that for later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sample_text = othello_lines[3792:3809]\n",
    "for line in sample_text:\n",
    "    print(line.rstrip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** Given the sample_text above, make a list of all words spoken by Othello"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "othellos_dialogue = []\n",
    "\n",
    "###Place your code here\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(othellos_dialogue)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code that we wrote above should (might?) be generalizable. Who knows. We'll have to check slowly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for line in othello_lines[:500]: #No reason to work with the full text while we're still learning\n",
    "    if 'OTHELLO.' in line:\n",
    "        print(line)\n",
    "        \n",
    "print('##########')\n",
    "\n",
    "for line in othello_lines[-100:]: #No reason to work with the full text while we're still learning\n",
    "    if 'OTHELLO.' in line:\n",
    "        print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks good to me. Of course, this is only finding the first line that Othello speaks, not any of his other lines. \n",
    "\n",
    "Let's go ahead and run our code on Othello to see how complex his vocabulary is!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "othellos_dialogue = []\n",
    "###Place your code here\n",
    "\n",
    "\n",
    "print(Counter(othellos_dialogue))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** How does Othello's word usage compare with Iago's? Who speaks more in this play? Who has a larger vocabulary?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###Place your code here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Additional exercises for those who are interested\n",
    "\n",
    "**Exercise:** A common way to summarize the complexity of text is by calculating its [entropy](https://en.wikipedia.org/wiki/Entropy_%28information_theory%29). Write a function to compare the entropy of Iago and Othello's speech. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###Place your code here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** This has all been very text-based without much graphical analysis. Can you plot a histogram of word frequencies? How about a cumulative distribution frequency plot? Does Othello's speech follow [Zipf's law](https://en.wikipedia.org/wiki/Zipf%27s_law)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###Place your code here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** Our first step toward analyzing Othello was to extract out the Othello specific text from the complete works file, which we did in an arbitrary way to make our lives easier. How would you do it in an automated fashion? Specifically, read the following file and return a _list_ of _tuples_ containing the (year,name) of every play within the file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "complete_works = open('../Data/Shakespeare.txt').readlines()\n",
    "play_list = []\n",
    "###Place your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** How well does the code that we wrote above work on Hamlet? Romeo and Juliet? Who has the biggest vocabulary in all of Shakespeare?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###Place your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

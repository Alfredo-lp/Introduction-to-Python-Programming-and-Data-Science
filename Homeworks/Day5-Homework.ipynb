{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 5 Homework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. requests\n",
    "\n",
    "Write a function that takes any url as a string and returns the response from a `GET` request.\n",
    "\n",
    "*Hint*: You can use http://httpbin.org/ to test your function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def get_response(url):\n",
    "    '''\n",
    "    Performs a GET request for a given url and returns the response.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    url : (str)\n",
    "        Web address we want to request\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    response : (requests.response)   \n",
    "        output of the request\n",
    "        \n",
    "    Notes:\n",
    "    ------\n",
    "    1. If the url is invalid or points to a non-existing address, your code\n",
    "        should return None.\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    # your code here\n",
    "    \n",
    "    \n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Beautiful Soup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 \n",
    "\n",
    "Write a function that converts Erik Durm's wikipedia page (the one we used in the [lecture](../Special-Topics/Web-Scraping.ipynb#Beautiful-Soup,-so-rich-and-green,-Waiting-in-a-hot-tureen!)) into a soup object and extracts the `<p>` element that starts with \"In the 2013â€“14 Bundesliga season...\". Your function must return the Beautiful Soup's `Tag` object itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import bs4\n",
    "\n",
    "def extract_bundesliga_p_tag(wiki_path):\n",
    "    '''\n",
    "    Extracts the <p> tag from ErikDurmWiki that starts with:\n",
    "    \"In the 2013-14 Bundesliga season.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    wiki_path : (str)\n",
    "        Path to Erik Durm's wikipedia page in the Data folder.\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    p_tag : (bs4.element.tag)   \n",
    "        Beautiful Soup's tag object containing the paragraph in question.\n",
    "    '''\n",
    "    \n",
    "    with open(wiki_path, \"r\") as wiki_file:\n",
    "        soup = bs4.BeautifulSoup(wiki_file.read())\n",
    "    \n",
    "    \n",
    "    # your code here\n",
    "    \n",
    "    \n",
    "    return p_tag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 2.2\n",
    "\n",
    "In the Data folder you will find another previously scraped webpage containing the lyrics to Pink Floyd's Wish You Were Here: `pink_floyd_wish.html`.\n",
    "\n",
    "Write a function that converts this page into a soup and returns a list with the song's title and lyrics. Format the lyrics as a list of strings, with each string being a line in the lyrics. Remove all newline characters, empty lines, and html tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import bs4 \n",
    "\n",
    "def extract_pink_floyd_lyrics(lyrics_path):\n",
    "    '''\n",
    "    Extracts the title and lyrics of Pink Floyd's Wish You Were Here song.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    lyrics_path : (str)\n",
    "        Path to the lyrics page in the Data folder.\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    lyrics_info : (list)\n",
    "        List where the first element is the song's title (string)\n",
    "        and second element is a list of strings with the lyrics\n",
    "    '''\n",
    "    \n",
    "    with open(lyrics_path, \"r\") as lyrics_file:\n",
    "        soup = bs4.BeautifulSoup(lyrics_file.read())\n",
    "\n",
    "        \n",
    "    # your code here\n",
    "\n",
    "    \n",
    "    return lyrics_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 \n",
    "\n",
    "In class you wrote a function that converted your Hexaco results page to a soup and extracted the `(name, your score)` pairs for each personality scale. \n",
    "\n",
    "Now write a function that extracts the `(name, median score)` pairs for each personality scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import bs4 \n",
    "\n",
    "def extract_median_scores(hexaco_path):\n",
    "    '''\n",
    "    Extracts the median scores as well as the name of each personality\n",
    "    scale from the hexaco's results page.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    hexaco_path : (str)\n",
    "        Path to the html page with your hexaco scores.\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    name_medians : (list of pairs)   \n",
    "        List of pairs (tuple or list), with each pair being: (scale name (str), median score (float))\n",
    "    '''\n",
    "\n",
    "    with open(hexaco_path, \"r\") as hexaco_file:\n",
    "        soup = bs4.BeautifulSoup(hexaco_file.read())\n",
    "    \n",
    "    # your code here\n",
    "    \n",
    "\n",
    "    return name_medians"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 5 Homework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. requests\n",
    "\n",
    "Write a function that takes any url as a string and returns the response from a `GET` request.\n",
    "\n",
    "*Hint*: You can use http://httpbin.org/ to test your function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def get_response(url):\n",
    "    '''\n",
    "    Performs a GET request for a given url and returns the response.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    url : (str)\n",
    "        web address we want to request\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    response : (requests.response)   \n",
    "        output of the request\n",
    "        \n",
    "    Notes:\n",
    "    ------\n",
    "    1. If the url is invalid or points to a non-existing address, your code\n",
    "        should return None.\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    # your code here\n",
    "    \n",
    "    \n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Beautiful Soup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 \n",
    "\n",
    "Write a function that converts Erik Durm's wikipedia page (the one we downloaded to the Data folder) into a soup object and extracts the `<p>` element that starts with \"In the 2013â€“14 Bundesliga season...\". Your function must return the Beautiful Soup's `Tag` object itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import bs4\n",
    "\n",
    "def extract_bundesliga_p_tag():\n",
    "    '''\n",
    "    Extracts the <p> tag from ErikDurmWiki that starts with:\n",
    "    \"In the 2013-14 Bundesliga season.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    None\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    p_tag : (bs4.element.tag)   \n",
    "        Beautiful Soup's tag object containing the paragraph in question.\n",
    "    '''\n",
    "    \n",
    "    with open(\"../Data/ErikDurmWiki\", \"r\") as wiki_file:\n",
    "        soup = bs4.BeautifulSoup(wiki_file.read())\n",
    "    \n",
    "    \n",
    "    # your code here\n",
    "    \n",
    "    \n",
    "    return p_tag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 2.2\n",
    "\n",
    "In the Data folder you will find another previously scraped webpage containing the lyrics to Pink Floyd's Wish You Were Here, one of the best songs of all time. Yes. Yes it is!\n",
    "\n",
    "Write a function that converts this page into a soup and returns a list with the song's title and lyrics. Format the lyrics as a list of strings, with each string being a line in the lyrics. Remove all newline characters, empty lines, and html tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import bs4 \n",
    "\n",
    "def extract_pink_floyd_lyrics():\n",
    "    '''\n",
    "    Extracts the title and lyrics of a very special Pink Floyd song\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    None\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    lyrics_info : (list)\n",
    "        List where the first element is the song's title (string)\n",
    "        and second element is a list of strings with the lyrics\n",
    "    '''\n",
    "    \n",
    "    with open(\"../Data/pink_floyd_wish.html\", \"r\") as lyrics_file:\n",
    "        soup = bs4.BeautifulSoup(lyrics_file.read())\n",
    "\n",
    "        \n",
    "    # your code here\n",
    "\n",
    "    \n",
    "    return lyrics_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 \n",
    "\n",
    "In class you wrote a function that converted your Hexaco results page to a soup and extracted the `(name, your score)` pairs for each personality scale. \n",
    "\n",
    "Now write a function that extracts the `(name, median score)` pairs for each personality scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import bs4 \n",
    "\n",
    "def extract_median_scores():\n",
    "    '''\n",
    "    Extracts the median scores as well as the name of each personality\n",
    "    scale from the hexaco's results page.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    None\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    name_medians : (list of 2-tuples)   \n",
    "        List of 2-tuples, each one will be: (scale name (str), median score (float))\n",
    "    '''\n",
    "\n",
    "    with open(\"../Data/my_hexaco.html\", \"r\") as hexaco_file:\n",
    "        soup = bs4.BeautifulSoup(hexaco_file.read())\n",
    "    \n",
    "    # your code here\n",
    "    \n",
    "\n",
    "    return name_medians"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

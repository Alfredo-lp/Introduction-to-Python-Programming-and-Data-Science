{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    @font-face {\n",
       "        font-family: \"Computer Modern\";\n",
       "        src: url('http://9dbb143991406a7c655e-aa5fcb0a5a4ec34cff238a2d56ca4144.r56.cf5.rackcdn.com/cmunss.otf');\n",
       "    }\n",
       "    @font-face {\n",
       "        font-family: \"Computer Modern\";\n",
       "        font-weight: bold;\n",
       "        src: url('http://9dbb143991406a7c655e-aa5fcb0a5a4ec34cff238a2d56ca4144.r56.cf5.rackcdn.com/cmunsx.otf');\n",
       "    }\n",
       "    @font-face {\n",
       "        font-family: \"Computer Modern\";\n",
       "        font-style: oblique;\n",
       "        src: url('http://9dbb143991406a7c655e-aa5fcb0a5a4ec34cff238a2d56ca4144.r56.cf5.rackcdn.com/cmunsi.otf');\n",
       "    }\n",
       "    @font-face {\n",
       "        font-family: \"Computer Modern\";\n",
       "        font-weight: bold;\n",
       "        font-style: oblique;\n",
       "        src: url('http://9dbb143991406a7c655e-aa5fcb0a5a4ec34cff238a2d56ca4144.r56.cf5.rackcdn.com/cmunso.otf');\n",
       "    }\n",
       "    h1 {\n",
       "        font-family: Helvetica, serif;\n",
       "    }\n",
       "    h4{\n",
       "        margin-top:12px;\n",
       "        margin-bottom: 3px;\n",
       "       }\n",
       "    div.text_cell_render{\n",
       "        font-family: Computer Modern, \"Helvetica Neue\", Arial, Helvetica, Geneva, sans-serif;\n",
       "        line-height: 145%;\n",
       "        font-size: 130%;\n",
       "        margin-left:auto;\n",
       "        margin-right:auto;\n",
       "    }\n",
       "    .CodeMirror{\n",
       "            font-family: \"Source Code Pro\", source-code-pro,Consolas, monospace;\n",
       "    }\n",
       "    .text_cell_render h5 {\n",
       "        font-weight: 300;\n",
       "        font-size: 22pt;\n",
       "        color: #4057A1;\n",
       "        font-style: italic;\n",
       "        margin-bottom: .5em;\n",
       "        margin-top: 0.5em;\n",
       "        display: block;\n",
       "    }\n",
       "    \n",
       "    .warning{\n",
       "        color: rgb( 240, 20, 20 )\n",
       "        }  \n",
       "</style>\n",
       "<script>\n",
       "    MathJax.Hub.Config({\n",
       "                        TeX: {\n",
       "                           extensions: [\"AMSmath.js\"]\n",
       "                           },\n",
       "                tex2jax: {\n",
       "                    inlineMath: [ ['$','$'], [\"\\\\(\",\"\\\\)\"] ],\n",
       "                    displayMath: [ ['$$','$$'], [\"\\\\[\",\"\\\\]\"] ]\n",
       "                },\n",
       "                displayAlign: 'center', // Change this to 'center' to center equations.\n",
       "                \"HTML-CSS\": {\n",
       "                    styles: {'.MathJax_Display': {\"margin\": 4}}\n",
       "                }\n",
       "        });\n",
       "</script>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.core.display import HTML\n",
    "def css_styling():\n",
    "    styles = open(\"../Data/www/styles/custom.css\", \"r\").read()\n",
    "    return HTML(styles)\n",
    "css_styling()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import requests \n",
    "import requests.auth\n",
    "import json\n",
    "#from PIL import Image\n",
    "#from io import BytesIO\n",
    "from IPython.display import display, Image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Reddit's API\n",
    "\n",
    "Reddit is an entertainment, social news networking service, and news website. Reddit's registered community members can submit content, such as text posts or direct links. Registered users can then vote submissions up or down to organize the posts and determine their position on the site's pages. The submissions with the most positive votes appear on the main page or the top of a category. \n",
    "\n",
    "Content entries are organized by areas of interest called \"subreddits\". The subreddit topics include news, gaming, movies, music, books, fitness, food, and photosharing, among many others.  \n",
    "\n",
    "Of course, what really get users of Reddit to come back are the [comments](https://www.reddit.com/r/aww/comments/4v00p4/owls_are_just_cats_with_wings_think_about_it/). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+++"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But enough of this. \n",
    "\n",
    "Reddit's API creates a new challenge for us.  In order to use it, we need to have an account and we need to **authenticate** our requests to the API.\n",
    "\n",
    "We are going to be doing a couple of different things here in order to authenticate our interactions with the API.  First, we will create a session. This is done using cookies. Fortunately, we do not need to worry about any of those details because `requests` will take care of it for us.\n",
    "\n",
    "Next, we will login to the reddit API and obtain a `modhash`. A `modhash` is a token that the reddit API requires to help prevent `Cross-Site Request Forgery` (CSRF), that is, an attack that forces an end user to execute unwanted actions on a web application in which they're currently authenticated. \n",
    "\n",
    "The following code was taken from https://github.com/reddit/reddit/wiki/OAuth2-Quick-Start-Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'reddit_auth.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-fd80e24c7984>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# load your authentication information\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'reddit_auth.json'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile_in\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mauth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_in\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'reddit_auth.json'"
     ]
    }
   ],
   "source": [
    "# app info\n",
    "app_name = 'nico101'\n",
    "redirect_uri = 'http://www.example.com/unused/redirect/uri'\n",
    "app_developers = ['lamaral1968']\n",
    "\n",
    "# load your authentication information\n",
    "with open('reddit_auth.json', 'r') as file_in:\n",
    "    auth = json.load(file_in)\n",
    "    \n",
    "client_auth = requests.auth.HTTPBasicAuth(auth['app_client_ID'], auth['app_client_secret']) \n",
    "post_data = {\"grant_type\": \"password\", \"username\": auth['username'], \"password\": auth['password']}\n",
    "headers = {\"User-Agent\": \"NICO_bot/0.1 by lamaral1968\"}\n",
    "response = requests.post(\"https://www.reddit.com/api/v1/access_token\", \n",
    "                         auth = client_auth, data = post_data, headers = headers)\n",
    "response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "access_token = response.json()['access_token']\n",
    "headers.update( {'Authorization': 'bearer ' + access_token } )\n",
    "response = requests.get(\"https://oauth.reddit.com/api/v1/me\", headers = headers)\n",
    "response.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If all we want to do is to search Reddit for content, then we do not need to authenticate.  Let's say that we want to look for posts to Reddit that feature puppies.  How would we go about doing it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_query = 'http://www.reddit.com/r/puppies/search.json'\n",
    "options = {'q': 'adorable', 'sort': 'new', 'restrict_sr': 'on'}\n",
    "\n",
    "response = requests.get( reddit_query, params = options )\n",
    "print(response.url)\n",
    "response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "goodies = response.json()\n",
    "print(type(goodies['data']['children']))\n",
    "stories = goodies['data']['children']\n",
    "print(stories[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`['data']['children']` is where the posts are.  We can see that we have a bunch of `keys` storing different types of information for each post.  We can look into more detail into the contents of our stories/posts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(stories[1].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(stories[0]['kind'])\n",
    "print(stories[0]['data'].keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(stories[0]['data']['author'])\n",
    "print(stories[0]['data']['id'])\n",
    "print(stories[0]['data']['score'])\n",
    "print(stories[0]['data']['thumbnail'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An interesting bit of information is that posts with images have URLs stored under the key `thumbnail`. Let's select all posts that have pictures.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i, story in enumerate(stories):\n",
    "    if 'http' in story['data']['thumbnail']:\n",
    "        figure_url = story['data']['thumbnail']\n",
    "        print(i, story['data']['name'], story['data']['created_utc'])\n",
    "        display(Image(url=figure_url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "index = 4\n",
    "print(stories[index]['kind'])\n",
    "print(stories[index]['data']['id'])\n",
    "print(stories[index]['data']['score'])\n",
    "print(stories[index]['data']['name'])\n",
    "print('http://www.reddit.com/' + stories[index]['data']['id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That one is clearly too cute to leave us unmoved. **We must upvote that post**, but how can we do it?\n",
    "\n",
    "First, it turns out you cannot vote on posts that are more than 6 months old.  All posts are archived after 6 months. So, we need to find a post that is younger than 6 months.  \n",
    "\n",
    "Fortunately, we've already checked the date and that post is from April 23, 2016.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(stories[index]['data']['name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to obtain all relevant information for voting. From the developer pages we learn that: \n",
    "\n",
    "    POST /api/vote  Cast a vote on a thing.\n",
    "\n",
    "    id should be the fullname of the Link or Comment to vote on.\n",
    "\n",
    "    dir indicates the direction of the vote. Voting 1 is an upvote, -1 is a downvote, and 0 is equivalent to \"un-voting\" by clicking again on a highlighted arrow.have to obtain the URL of the post.\n",
    "\n",
    "`fullname` is created by adding the `kind` and the `id`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = stories[index]['data']['name']\n",
    "vote = requests.post('https://oauth.reddit.com/api/vote', headers = headers, params = {'id': name, 'dir': 1} )\n",
    "print(vote.url)\n",
    "print(vote.status_code)\n",
    "print(vote.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Excellent! We've now voted on that adorable post! We've also successfully `POST`ed data using an API for the first time also. \n",
    "\n",
    "While we've had fun exploring this example, all APIs work on these exact same principles (some are just documented better than others) so you're now equipped to work with APIs all over the web!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    @font-face {\n",
       "        font-family: \"Computer Modern\";\n",
       "        src: url('http://9dbb143991406a7c655e-aa5fcb0a5a4ec34cff238a2d56ca4144.r56.cf5.rackcdn.com/cmunss.otf');\n",
       "    }\n",
       "    @font-face {\n",
       "        font-family: \"Computer Modern\";\n",
       "        font-weight: bold;\n",
       "        src: url('http://9dbb143991406a7c655e-aa5fcb0a5a4ec34cff238a2d56ca4144.r56.cf5.rackcdn.com/cmunsx.otf');\n",
       "    }\n",
       "    @font-face {\n",
       "        font-family: \"Computer Modern\";\n",
       "        font-style: oblique;\n",
       "        src: url('http://9dbb143991406a7c655e-aa5fcb0a5a4ec34cff238a2d56ca4144.r56.cf5.rackcdn.com/cmunsi.otf');\n",
       "    }\n",
       "    @font-face {\n",
       "        font-family: \"Computer Modern\";\n",
       "        font-weight: bold;\n",
       "        font-style: oblique;\n",
       "        src: url('http://9dbb143991406a7c655e-aa5fcb0a5a4ec34cff238a2d56ca4144.r56.cf5.rackcdn.com/cmunso.otf');\n",
       "    }\n",
       "    h1 {\n",
       "        font-family: Helvetica, serif;\n",
       "    }\n",
       "    h4{\n",
       "        margin-top:12px;\n",
       "        margin-bottom: 3px;\n",
       "       }\n",
       "    div.text_cell_render{\n",
       "        font-family: Computer Modern, \"Helvetica Neue\", Arial, Helvetica, Geneva, sans-serif;\n",
       "        line-height: 145%;\n",
       "        font-size: 130%;\n",
       "        margin-left:auto;\n",
       "        margin-right:auto;\n",
       "    }\n",
       "    .CodeMirror{\n",
       "            font-family: \"Source Code Pro\", source-code-pro,Consolas, monospace;\n",
       "    }\n",
       "    .text_cell_render h5 {\n",
       "        font-weight: 300;\n",
       "        font-size: 22pt;\n",
       "        color: #4057A1;\n",
       "        font-style: italic;\n",
       "        margin-bottom: .5em;\n",
       "        margin-top: 0.5em;\n",
       "        display: block;\n",
       "    }\n",
       "    \n",
       "    .warning{\n",
       "        color: rgb( 240, 20, 20 )\n",
       "        }  \n",
       "</style>\n",
       "<script>\n",
       "    MathJax.Hub.Config({\n",
       "                        TeX: {\n",
       "                           extensions: [\"AMSmath.js\"]\n",
       "                           },\n",
       "                tex2jax: {\n",
       "                    inlineMath: [ ['$','$'], [\"\\\\(\",\"\\\\)\"] ],\n",
       "                    displayMath: [ ['$$','$$'], [\"\\\\[\",\"\\\\]\"] ]\n",
       "                },\n",
       "                displayAlign: 'center', // Change this to 'center' to center equations.\n",
       "                \"HTML-CSS\": {\n",
       "                    styles: {'.MathJax_Display': {\"margin\": 4}}\n",
       "                }\n",
       "        });\n",
       "</script>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.core.display import HTML\n",
    "from IPython.lib.display import YouTubeVideo\n",
    "\n",
    "\n",
    "def css_styling():\n",
    "    styles = open(\"../styles/custom.css\", \"r\").read()\n",
    "    return HTML(styles)\n",
    "css_styling()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regressions!\n",
    "\n",
    "Many of you have created a linear regression before, although not all of you may know that you did it. The basic idea is pretty simple, we want to determine the linear relationship between some variable $x$ and another variable $y$. \n",
    "\n",
    "Sounds familiar right? All I'm describing is the equation $y = mx + b$ that we learned back in high school. This linear model describes the relationship between some independent $x$ variable and its dependent $y$.\n",
    "\n",
    "Fitting a regression model is common in many disciplines, so I'm going to show you how to do that in Python now. I want to explain enough of the mathematical background such that everyone can follow along, but this isn't meant as a proper explanation of the underlying statistics or when you should use a regression model. If you're not familiar with this model or the underlying statistics and want to learn more I recommend this [statistics textbook](http://www.amazon.com/Statistics-4th-Edition-David-Freedman/dp/0393929728)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#But...math!\n",
    "\n",
    "I know, so let's start with a simple, concrete example. Let's say that someone's High-School Senior GPA is almost exactly the same as their first year College GPA. This means that if we wanted to predict a student's first year gpa ($y$) we would guess based on their High school GPA ($x$). More simply, $y = x$.\n",
    "\n",
    "I'll create that data now with Numpy, but instead I'll just apply a little bit of noise to the values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "#We turn off the latex usage in matplotlib because LaTeX doesn't know\n",
    "#how to handle a '_' character without it being escaped with a backslash\n",
    "#Since we use '_' in column names typically this can be a bit of a problem\n",
    "#If we don't turn this off\n",
    "mpl.rc('text', usetex=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#I will create 100 gpas, with a random probability\n",
    "high_school_gpas = np.random.uniform(0, 4, 100)\n",
    "#The college gpas are created by adding some noise\n",
    "college_gpas = high_school_gpas + np.random.normal(0, 0.2, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's plot the relationship just so it's clear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.scatter(high_school_gpas, college_gpas, color='steelblue')\n",
    "plt.ylabel('College GPA')\n",
    "plt.xlabel('High School GPA')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's say that we didn't create this data and we wanted to identify the relationship between High School and College GPA. We can do that by fitting a linear model to the data.\n",
    "\n",
    "With Python we can fit a Linear Model using the `statsmodels` library. Fitting a linear model involves using [Ordinary Least Squares](https://en.wikipedia.org/wiki/Ordinary_least_squares) to identify the parameters. In this lecture I won't go over how this works, but you should look into it later if you plan on fitting linear models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First what I do is add a constant to the independent dataset. Without this we are just modelling $y=mx$, instead of $y=mx+b$. Our example doesn't need this constant, but I want to show you how to do it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = sm.add_constant(high_school_gpas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we create the ordinary least squares regression, this is our `model`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "simdata_model = sm.OLS(college_gpas, X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we fit the model, this becomes our result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "simdata_result = simdata_model.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fitted result has a number of features, but the one that we care about most is the `summary()`. This tells us about our fitted model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "simdata_result.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does anyone know what all of these features mean?\n",
    "\n",
    "**That's insane if you do right now!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can plot the best-fit line along with the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Here is the data again\n",
    "plt.scatter(high_school_gpas, college_gpas, color='steelblue')\n",
    "#Now for our equation\n",
    "sim_x = np.linspace(0, 4, 100)\n",
    "sim_y = 1.0262 * sim_x - 0.0608\n",
    "plt.plot(sim_x, sim_y, color='black', linewidth=2)\n",
    "#Our labelled axes\n",
    "plt.ylabel('College GPA')\n",
    "plt.xlabel('High School GPA')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pretty darn good!\n",
    "\n",
    "But this isn't actually real data. I've downloaded some real data that was a part of an introductory statistics textbook. Let's load that csv with Pandas right now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('../Data/student_gpa_data.csv')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "In this dataframe we have 10 columns:\n",
    "\n",
    "    GPA - 1st Year College GPA\n",
    "    HSGPA - High School GPA\n",
    "    SATV - SAT Verbal Score\n",
    "    SATM - SAT Math Score\n",
    "    Male - Male (1) or Female (0)\n",
    "    HU - Number of credit hours earned in humanities courses in high school.\n",
    "    SS - Number of credit hours earned in social science courses in high school.\n",
    "    FirstGen - First Generation College Student\n",
    "    White - White (1) or Other Ethnicity (0) \n",
    "    CollegeBound - 1 = attended a high school where >=50% students intended to go on to college, 0 = otherwise\n",
    "    \n",
    "But right now, let's just look at the relationship between High School GPA and College GPA like we did previously.\n",
    "\n",
    "Like always we should take a look at the raw data before we try to model it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.plot(kind='scatter', x = 'HSGPA', y = 'GPA', color='steelblue')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yikes! Looks like my initially generated data was a bit optimistic....\n",
    "\n",
    "Let's try fitting a linear model to this dataset and see what it looks like."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Now here's a cool thing, there are actually two ways to run regressions with statsmodels. The first one is by importing the vanilla `statsmodels` from `statsmodels.api`. The other way is by calling `statsmodels` formulas, which are from `statmodels.formula.api`. Why is there this crazy naming scheme? ...I can't really tell you actually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The great thing about the formula is that it works directly with a Dataframe! We just have to learn a little bit of syntax. I'll show you how it works first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "realdata_model = smf.ols(formula = 'GPA ~ HSGPA', data = df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can type out a linear formula and it will automatically add the constant that we previously had to add manually. When we write a formula it is set up as:\n",
    "\n",
    "    dependent variable = independent variable\n",
    "    \n",
    "but the equals sign is replaced by a `~`. All we need to do is tell it the name of the columns in the dataframe that we want it to use in the model.\n",
    "\n",
    "We also tell the model that the data is coming from the dataframe.\n",
    "\n",
    "Now we can fit the model just like before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "realdata_result = realdata_model.fit()\n",
    "realdata_result.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### So what does this all mean?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "First, we might notice the difference in the slope between the simulated data model line and the real data model line. We can show that here quickly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Here I define our x and y variables for the real data\n",
    "real_x = np.linspace(df.HSGPA.min(), 4, 100)\n",
    "real_y = realdata_result.params['HSGPA'] * real_x + realdata_result.params['Intercept']\n",
    "#Here I redefine our simulated y to use the same x-range as our real data\n",
    "sim_y = simdata_result.params[1] * real_x + simdata_result.params[0]\n",
    "#Now I plot the lines\n",
    "plt.plot(real_x, real_y, color='black', label='Real Data', linewidth=3)\n",
    "plt.plot(real_x, sim_y, color='steelblue', label='Fake Data', linewidth=3)\n",
    "plt.legend(loc='best')\n",
    "plt.ylabel('College GPA')\n",
    "plt.xlabel('High School GPA')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that the slope of a line is defined as the rise over the run (or $\\frac{\\Delta y}{\\Delta x}$)?\n",
    "\n",
    "This plot shows that in the fake data for every point increase in High School GPA there was an **equal** point increase in College GPA.\n",
    "\n",
    "In the real data, the slope of the line is not as steep - meaning that the College GPA *rises* less than the High School GPA *runs*. So if a student had a High School GPA of 4.0, we would predict a College GPA of 3.4. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "realdata_result.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we should notice that this model doesn't explain nearly as much of the real data as the synthetic data. We can tell this by the R-squared value. \n",
    "\n",
    "With real data, high school GPA only predicts 20% of the variance in college GPA.\n",
    "\n",
    "This becomes a bit more intuitive when we plot the regression line against the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Here is the data again\n",
    "ax = df.plot(kind='scatter', x = 'HSGPA', y = 'GPA', color='steelblue')\n",
    "#Now for our equation\n",
    "plt.plot(real_x, real_y, color='black', linewidth=2)\n",
    "#Our labelled axes\n",
    "plt.ylabel('College GPA')\n",
    "plt.xlabel('High School GPA')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We can tell by looking at the data, that there is much more 'spread' or *variability* in the vertical axis than the line accounts for. This makes sense given the definition of the [$R^2$ coefficient](https://en.wikipedia.org/wiki/Coefficient_of_determination). This measure compares the distance from each point to the fitted line against the total variability in the dependent data. We would have $R^2=1.0$ if all of the datapoints sat directly on the predicted line."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means that in the real world, High School GPA is not solely predictive of a student's College GPA.\n",
    "\n",
    "I wonder why?\n",
    "\n",
    "Maybe it's because some students may be bored with regular instruction in High School and don't pay attention or turn in assignments. Maybe if we used both the High School GPA and the SAT scores we would be able to predict the College GPA better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_scores_model = smf.ols(formula='GPA ~ HSGPA + SATV + SATM', data=df)\n",
    "test_scores_result = test_scores_model.fit()\n",
    "test_scores_result.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting! Judging by the $R^2$, there was a minor increase in how well this new model fits the data. However, the results weren't quite what we expected!\n",
    "\n",
    "There is a *small* but *significant* positive relationship between the SAT Verbal score and a student's First Year College GPA. However, there is *no significant* relationship with the SAT Math score.\n",
    "\n",
    "Guess being good at math only goes so far, huh?\n",
    "\n",
    "Well, if our SAT test scores only have a very minor effect on our College GPA I wonder what being a first generation college student will do. It's possible that people who are the first in their family to go to college work harder than those of us who had parents go."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "firstgen_model = smf.ols(formula='GPA ~ HSGPA + SATV + FirstGen', data=df)\n",
    "firstgen_result = firstgen_model.fit()\n",
    "firstgen_result.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guess I was wrong! Being a first generation college student has a *significant, negative* relationship with College GPA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's plot this model. \n",
    "\n",
    "But wait, how do we plot it now that the x-axis has three components and isn't just the High School GPA?\n",
    "\n",
    "What we do is calculate the x position for each data point we have and then plot that x-value against the College GPA.\n",
    "\n",
    "Let's write that function now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def calculate_firstgen_x_value(row, params = firstgen_result.params):\n",
    "    '''\n",
    "    input:\n",
    "        row - one row of student data from the pandas dataframe\n",
    "        params - the model parameters dictionary\n",
    "    output:\n",
    "        modelx - the calculated x point for the model\n",
    "    '''\n",
    "    columns = ['HSGPA', 'SATV', 'FirstGen']\n",
    "    modelx = params['Intercept']\n",
    "    for col in columns:\n",
    "        modelx += params[col] * row[col]\n",
    "    return modelx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we will `apply` it to the dataframe. I haven't covered how to do this yet, but I will now!\n",
    "\n",
    "In Pandas we can `apply` our own functions to a dataframe. We can apply them to a single column (in which case the input value to the function is a single variable) or to the entire dataframe (in which case the input value to the function is a `Series` and is either a row or column in the dataframe).\n",
    "\n",
    "Here I need to access multiple columns of data for each student so I will `apply` the `calculate_firstgen_x_value()` function to the entire dataframe. I also want to calculate each student's value so I need to apply this to the rows. To pick `rows` instead of columns we need to change the `axis` argument to `1`.\n",
    "\n",
    "Since I want to keep this value I'll set the output equal to a new column name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['firstgen_model'] = df.apply(calculate_firstgen_x_value, axis = 1)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.plot(kind='scatter', x='firstgen_model', y='GPA', color='steelblue')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that when we transform the x data values the spread in the y-axis is much smaller than when we first modeled the relationship between College GPA and the High School GPA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, we could also use the built-in plotting from `statsmodels` too. It will only show a single independent variable at a time, but it's a really quick way to plot!\n",
    "\n",
    "The first plot we can use is with `plot_fit()`. The `plot_fit()` funciton shows the real data points and the predicted data point (with confidence intervals)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sm.graphics.plot_fit(firstgen_result, 'HSGPA');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The other plotting function is more of a diagnostic one for users to evaluate how good their model is. It's the `plot_regress_exog` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (8,8))\n",
    "sm.graphics.plot_regress_exog(firstgen_result, 'HSGPA', fig=fig);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

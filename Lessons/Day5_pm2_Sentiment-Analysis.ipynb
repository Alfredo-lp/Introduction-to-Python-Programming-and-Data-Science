{"cells": [{"cell_type": "code", "metadata": {"collapsed": false}, "source": ["from IPython.core.display import HTML\n", "def css_styling():\n", "    styles = open(\"../Data/www/styles/custom.css\", \"r\").read()\n", "    return HTML(styles)\n", "css_styling()"], "outputs": [{"metadata": {}, "output_type": "execute_result", "data": {"text/plain": ["<IPython.core.display.HTML object>"], "text/html": ["<style>\n", "    @font-face {\n", "        font-family: \"Computer Modern\";\n", "        src: url('http://9dbb143991406a7c655e-aa5fcb0a5a4ec34cff238a2d56ca4144.r56.cf5.rackcdn.com/cmunss.otf');\n", "    }\n", "    @font-face {\n", "        font-family: \"Computer Modern\";\n", "        font-weight: bold;\n", "        src: url('http://9dbb143991406a7c655e-aa5fcb0a5a4ec34cff238a2d56ca4144.r56.cf5.rackcdn.com/cmunsx.otf');\n", "    }\n", "    @font-face {\n", "        font-family: \"Computer Modern\";\n", "        font-style: oblique;\n", "        src: url('http://9dbb143991406a7c655e-aa5fcb0a5a4ec34cff238a2d56ca4144.r56.cf5.rackcdn.com/cmunsi.otf');\n", "    }\n", "    @font-face {\n", "        font-family: \"Computer Modern\";\n", "        font-weight: bold;\n", "        font-style: oblique;\n", "        src: url('http://9dbb143991406a7c655e-aa5fcb0a5a4ec34cff238a2d56ca4144.r56.cf5.rackcdn.com/cmunso.otf');\n", "    }\n", "    h1 {\n", "        font-family: Helvetica, serif;\n", "    }\n", "    h4{\n", "        margin-top:12px;\n", "        margin-bottom: 3px;\n", "       }\n", "    div.text_cell_render{\n", "        font-family: Computer Modern, \"Helvetica Neue\", Arial, Helvetica, Geneva, sans-serif;\n", "        line-height: 145%;\n", "        font-size: 130%;\n", "        margin-left:auto;\n", "        margin-right:auto;\n", "    }\n", "    .CodeMirror{\n", "            font-family: \"Source Code Pro\", source-code-pro,Consolas, monospace;\n", "    }\n", "    .text_cell_render h5 {\n", "        font-weight: 300;\n", "        font-size: 22pt;\n", "        color: #4057A1;\n", "        font-style: italic;\n", "        margin-bottom: .5em;\n", "        margin-top: 0.5em;\n", "        display: block;\n", "    }\n", "    \n", "    .warning{\n", "        color: rgb( 240, 20, 20 )\n", "        }  \n", "</style>\n", "<script>\n", "    MathJax.Hub.Config({\n", "                        TeX: {\n", "                           extensions: [\"AMSmath.js\"]\n", "                           },\n", "                tex2jax: {\n", "                    inlineMath: [ ['$','$'], [\"\\\\(\",\"\\\\)\"] ],\n", "                    displayMath: [ ['$$','$$'], [\"\\\\[\",\"\\\\]\"] ]\n", "                },\n", "                displayAlign: 'center', // Change this to 'center' to center equations.\n", "                \"HTML-CSS\": {\n", "                    styles: {'.MathJax_Display': {\"margin\": 4}}\n", "                }\n", "        });\n", "</script>\n"]}, "execution_count": 1}], "execution_count": 1}, {"cell_type": "markdown", "metadata": {"collapsed": true}, "source": ["# Synopsis\n", "\n", "So far we have essentially only learned how to parse and enumerate the number of words in text (doesn't sound like much, huh? But that alone comprises a large amount of basic textual analysis). In this unit we will go a bit further and cover:\n", "\n", "1. Preparing text for further analysis\n", "2. Analyzing sentiment\n", "\n", "We will also talk about how difficult advanced analysis of unstructured text is despite its appearance as an 'easy' task."]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Text as Data\n", "\n", "As we discussed this morning, analyzing text is not nearly as simple as it would appear. In this module we're going to learn the basics of examining sentiment in text. \n", "\n", "We'll be working with an example text:\n", "\n", "\"Adam is totally cool. You should come to his class.\"\n", "\n", "To begin with, let's answer some basic questions. \n", "\n", "* Is this overall sentence positive or negative?\n", "* Which words make it positive or negative?\n", "* Do all words have a positive or negative affect?"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Now the question becomes, how can we automate the analysis of the sentiment in the text?\n", "\n", "There are actually many ways to rate the positive or negative sentiment of a word, more complicated approaches involve machine-learning, but we'll start simply with using a dictionary.\n", "\n", "There are many dictionaries that people have created to analyze sentiment, for our uses today we will use the AFINN dictionary that is provided in `Data/`"]}, {"cell_type": "code", "metadata": {"collapsed": false}, "source": ["afinn_list = [l.strip().split() for l in open('../Data/Day5-Text-Analysis/AFINN/AFINN-111.txt', encoding = 'utf-8').readlines()]\n", "print(afinn_list[:10])"], "outputs": [{"output_type": "stream", "name": "stdout", "text": ["[['abandon', '-2'], ['abandoned', '-2'], ['abandons', '-2'], ['abducted', '-2'], ['abduction', '-2'], ['abductions', '-2'], ['abhor', '-3'], ['abhorred', '-3'], ['abhorrent', '-3'], ['abhors', '-3']]\n"]}], "execution_count": 2}, {"cell_type": "markdown", "metadata": {}, "source": ["The AFINN dictionary is relatively simple. It gives a word and then it's numeric score of postivity or negativity (negative words are negative numbers).\n", "\n", "But we really need to convert it to a dictionary if it's going to be useful to us (list lookups are expensive!)"]}, {"cell_type": "code", "metadata": {"collapsed": false}, "source": ["#Place your code here\n", "afinn = {}\n", "for item in afinn_list[:10]:\n", "    key = item[0]\n", "    score = int(item[1])\n", "    afinn[key] = score\n", "    \n", "print(afinn)"], "outputs": [{"output_type": "stream", "name": "stdout", "text": ["{'abhor': -3, 'abhorred': -3, 'abhors': -3, 'abhorrent': -3, 'abandon': -2, 'abducted': -2, 'abduction': -2, 'abandoned': -2, 'abandons': -2, 'abductions': -2}\n"]}], "execution_count": 3}, {"cell_type": "markdown", "metadata": {}, "source": ["\n", "To start with, let's look at the words with sentiment in the example text."]}, {"cell_type": "code", "metadata": {"collapsed": true}, "source": ["example_text = \"Adam is totally cool. You should come to his class\""], "outputs": [], "execution_count": 5}, {"cell_type": "code", "metadata": {"collapsed": false}, "source": ["###Place your code here\n", "words = example_text.split()\n", "print(words)"], "outputs": [{"output_type": "stream", "name": "stdout", "text": ["['Adam', 'is', 'totally', 'cool.', 'You', 'should', 'come', 'to', 'his', 'class']\n"]}], "execution_count": 6}, {"cell_type": "code", "metadata": {"collapsed": false}, "source": ["example_words = [word.strip('. ') for word in example_text.split(' ')]\n", "for word in example_words:\n", "    if word in afinn:\n", "        print('--- ', word, '\\t', afinn[word.lower()])\n", "    else:\n", "        print(word)"], "outputs": [{"output_type": "stream", "name": "stdout", "text": ["Adam\n", "is\n", "totally\n", "---  cool \t 1\n", "You\n", "should\n", "come\n", "to\n", "his\n", "class\n"]}], "execution_count": 11}, {"cell_type": "markdown", "metadata": {}, "source": ["As we can see, only word assigned a sentiment score is \"cool\".\n", "\n", "`Adam` is a proper noun, `You` is a pronoun, `his` is a possessive - so no sentiment there\n", "\n", "`is`, `should`, and `come` are the verbs - so no sentiment\n", "\n", "`to` is a preposition\n", "\n", "`class` is a noun\n", "\n", "`totally` is a different story though. It's an adverb and is modifying `cool`, which is positive. However, the sentiment of `totally` is entirely dependent on the word that it is modifying. So on its own, it it doesn't actually have a score.\n", "\n", "So we can judge that this overall text is mildly positive, there isn't that much to go on though since it's such a small piece! \n", "\n", "There could be more that we could write to understand `totally` and it's relationship to `cool`, but we'll save that for later. Right now we're going to stick to analyzing unigrams (single words) as just a bag (which actually works really well as a first approximation!"]}, {"cell_type": "markdown", "metadata": {}, "source": ["But one thing you'll notice is that there are a lot of words that don't add meaning that we're checking to see if they do have meaning. \n", "\n", "One set of words that doesn't really help are called stopwords. Stop words are the most common words in a language and don't really have a lot of meaning when it comes to the analysis of setniment in text.\n", "\n", "For our lesson today we will need to download the `stopwords` corpora."]}, {"cell_type": "code", "metadata": {"collapsed": false}, "source": ["# A new window will open. Select only the materials that appear in the book\n", "import nltk\n", "nltk.download()"], "outputs": [{"output_type": "stream", "name": "stdout", "text": ["showing info http://www.nltk.org/nltk_data/\n"]}, {"metadata": {}, "output_type": "execute_result", "data": {"text/plain": ["True"]}, "execution_count": 12}], "execution_count": 12}, {"cell_type": "markdown", "metadata": {}, "source": ["Excellent! Now we will need to import our corpora."]}, {"cell_type": "code", "metadata": {"collapsed": true}, "source": ["from nltk.corpus import stopwords"], "outputs": [], "execution_count": 13}, {"cell_type": "markdown", "metadata": {}, "source": ["And let's take a look at what is inside the stopwords list."]}, {"cell_type": "code", "metadata": {"collapsed": false}, "source": ["stopwords.words()"], "outputs": [{"metadata": {}, "output_type": "execute_result", "data": {"text/plain": ["['og',\n", " 'i',\n", " 'jeg',\n", " 'det',\n", " 'at',\n", " 'en',\n", " 'den',\n", " 'til',\n", " 'er',\n", " 'som',\n", " 'p\u00e5',\n", " 'de',\n", " 'med',\n", " 'han',\n", " 'af',\n", " 'for',\n", " 'ikke',\n", " 'der',\n", " 'var',\n", " 'mig',\n", " 'sig',\n", " 'men',\n", " 'et',\n", " 'har',\n", " 'om',\n", " 'vi',\n", " 'min',\n", " 'havde',\n", " 'ham',\n", " 'hun',\n", " 'nu',\n", " 'over',\n", " 'da',\n", " 'fra',\n", " 'du',\n", " 'ud',\n", " 'sin',\n", " 'dem',\n", " 'os',\n", " 'op',\n", " 'man',\n", " 'hans',\n", " 'hvor',\n", " 'eller',\n", " 'hvad',\n", " 'skal',\n", " 'selv',\n", " 'her',\n", " 'alle',\n", " 'vil',\n", " 'blev',\n", " 'kunne',\n", " 'ind',\n", " 'n\u00e5r',\n", " 'v\u00e6re',\n", " 'dog',\n", " 'noget',\n", " 'ville',\n", " 'jo',\n", " 'deres',\n", " 'efter',\n", " 'ned',\n", " 'skulle',\n", " 'denne',\n", " 'end',\n", " 'dette',\n", " 'mit',\n", " 'ogs\u00e5',\n", " 'under',\n", " 'have',\n", " 'dig',\n", " 'anden',\n", " 'hende',\n", " 'mine',\n", " 'alt',\n", " 'meget',\n", " 'sit',\n", " 'sine',\n", " 'vor',\n", " 'mod',\n", " 'disse',\n", " 'hvis',\n", " 'din',\n", " 'nogle',\n", " 'hos',\n", " 'blive',\n", " 'mange',\n", " 'ad',\n", " 'bliver',\n", " 'hendes',\n", " 'v\u00e6ret',\n", " 'thi',\n", " 'jer',\n", " 's\u00e5dan',\n", " 'de',\n", " 'en',\n", " 'van',\n", " 'ik',\n", " 'te',\n", " 'dat',\n", " 'die',\n", " 'in',\n", " 'een',\n", " 'hij',\n", " 'het',\n", " 'niet',\n", " 'zijn',\n", " 'is',\n", " 'was',\n", " 'op',\n", " 'aan',\n", " 'met',\n", " 'als',\n", " 'voor',\n", " 'had',\n", " 'er',\n", " 'maar',\n", " 'om',\n", " 'hem',\n", " 'dan',\n", " 'zou',\n", " 'of',\n", " 'wat',\n", " 'mijn',\n", " 'men',\n", " 'dit',\n", " 'zo',\n", " 'door',\n", " 'over',\n", " 'ze',\n", " 'zich',\n", " 'bij',\n", " 'ook',\n", " 'tot',\n", " 'je',\n", " 'mij',\n", " 'uit',\n", " 'der',\n", " 'daar',\n", " 'haar',\n", " 'naar',\n", " 'heb',\n", " 'hoe',\n", " 'heeft',\n", " 'hebben',\n", " 'deze',\n", " 'u',\n", " 'want',\n", " 'nog',\n", " 'zal',\n", " 'me',\n", " 'zij',\n", " 'nu',\n", " 'ge',\n", " 'geen',\n", " 'omdat',\n", " 'iets',\n", " 'worden',\n", " 'toch',\n", " 'al',\n", " 'waren',\n", " 'veel',\n", " 'meer',\n", " 'doen',\n", " 'toen',\n", " 'moet',\n", " 'ben',\n", " 'zonder',\n", " 'kan',\n", " 'hun',\n", " 'dus',\n", " 'alles',\n", " 'onder',\n", " 'ja',\n", " 'eens',\n", " 'hier',\n", " 'wie',\n", " 'werd',\n", " 'altijd',\n", " 'doch',\n", " 'wordt',\n", " 'wezen',\n", " 'kunnen',\n", " 'ons',\n", " 'zelf',\n", " 'tegen',\n", " 'na',\n", " 'reeds',\n", " 'wil',\n", " 'kon',\n", " 'niets',\n", " 'uw',\n", " 'iemand',\n", " 'geweest',\n", " 'andere',\n", " 'i',\n", " 'me',\n", " 'my',\n", " 'myself',\n", " 'we',\n", " 'our',\n", " 'ours',\n", " 'ourselves',\n", " 'you',\n", " 'your',\n", " 'yours',\n", " 'yourself',\n", " 'yourselves',\n", " 'he',\n", " 'him',\n", " 'his',\n", " 'himself',\n", " 'she',\n", " 'her',\n", " 'hers',\n", " 'herself',\n", " 'it',\n", " 'its',\n", " 'itself',\n", " 'they',\n", " 'them',\n", " 'their',\n", " 'theirs',\n", " 'themselves',\n", " 'what',\n", " 'which',\n", " 'who',\n", " 'whom',\n", " 'this',\n", " 'that',\n", " 'these',\n", " 'those',\n", " 'am',\n", " 'is',\n", " 'are',\n", " 'was',\n", " 'were',\n", " 'be',\n", " 'been',\n", " 'being',\n", " 'have',\n", " 'has',\n", " 'had',\n", " 'having',\n", " 'do',\n", " 'does',\n", " 'did',\n", " 'doing',\n", " 'a',\n", " 'an',\n", " 'the',\n", " 'and',\n", " 'but',\n", " 'if',\n", " 'or',\n", " 'because',\n", " 'as',\n", " 'until',\n", " 'while',\n", " 'of',\n", " 'at',\n", " 'by',\n", " 'for',\n", " 'with',\n", " 'about',\n", " 'against',\n", " 'between',\n", " 'into',\n", " 'through',\n", " 'during',\n", " 'before',\n", " 'after',\n", " 'above',\n", " 'below',\n", " 'to',\n", " 'from',\n", " 'up',\n", " 'down',\n", " 'in',\n", " 'out',\n", " 'on',\n", " 'off',\n", " 'over',\n", " 'under',\n", " 'again',\n", " 'further',\n", " 'then',\n", " 'once',\n", " 'here',\n", " 'there',\n", " 'when',\n", " 'where',\n", " 'why',\n", " 'how',\n", " 'all',\n", " 'any',\n", " 'both',\n", " 'each',\n", " 'few',\n", " 'more',\n", " 'most',\n", " 'other',\n", " 'some',\n", " 'such',\n", " 'no',\n", " 'nor',\n", " 'not',\n", " 'only',\n", " 'own',\n", " 'same',\n", " 'so',\n", " 'than',\n", " 'too',\n", " 'very',\n", " 's',\n", " 't',\n", " 'can',\n", " 'will',\n", " 'just',\n", " 'don',\n", " 'should',\n", " 'now',\n", " 'd',\n", " 'll',\n", " 'm',\n", " 'o',\n", " 're',\n", " 've',\n", " 'y',\n", " 'ain',\n", " 'aren',\n", " 'couldn',\n", " 'didn',\n", " 'doesn',\n", " 'hadn',\n", " 'hasn',\n", " 'haven',\n", " 'isn',\n", " 'ma',\n", " 'mightn',\n", " 'mustn',\n", " 'needn',\n", " 'shan',\n", " 'shouldn',\n", " 'wasn',\n", " 'weren',\n", " 'won',\n", " 'wouldn',\n", " 'olla',\n", " 'olen',\n", " 'olet',\n", " 'on',\n", " 'olemme',\n", " 'olette',\n", " 'ovat',\n", " 'ole',\n", " 'oli',\n", " 'olisi',\n", " 'olisit',\n", " 'olisin',\n", " 'olisimme',\n", " 'olisitte',\n", " 'olisivat',\n", " 'olit',\n", " 'olin',\n", " 'olimme',\n", " 'olitte',\n", " 'olivat',\n", " 'ollut',\n", " 'olleet',\n", " 'en',\n", " 'et',\n", " 'ei',\n", " 'emme',\n", " 'ette',\n", " 'eiv\u00e4t',\n", " 'min\u00e4',\n", " 'minun',\n", " 'minut',\n", " 'minua',\n", " 'minussa',\n", " 'minusta',\n", " 'minuun',\n", " 'minulla',\n", " 'minulta',\n", " 'minulle',\n", " 'sin\u00e4',\n", " 'sinun',\n", " 'sinut',\n", " 'sinua',\n", " 'sinussa',\n", " 'sinusta',\n", " 'sinuun',\n", " 'sinulla',\n", " 'sinulta',\n", " 'sinulle',\n", " 'h\u00e4n',\n", " 'h\u00e4nen',\n", " 'h\u00e4net',\n", " 'h\u00e4nt\u00e4',\n", " 'h\u00e4ness\u00e4',\n", " 'h\u00e4nest\u00e4',\n", " 'h\u00e4neen',\n", " 'h\u00e4nell\u00e4',\n", " 'h\u00e4nelt\u00e4',\n", " 'h\u00e4nelle',\n", " 'me',\n", " 'meid\u00e4n',\n", " 'meid\u00e4t',\n", " 'meit\u00e4',\n", " 'meiss\u00e4',\n", " 'meist\u00e4',\n", " 'meihin',\n", " 'meill\u00e4',\n", " 'meilt\u00e4',\n", " 'meille',\n", " 'te',\n", " 'teid\u00e4n',\n", " 'teid\u00e4t',\n", " 'teit\u00e4',\n", " 'teiss\u00e4',\n", " 'teist\u00e4',\n", " 'teihin',\n", " 'teill\u00e4',\n", " 'teilt\u00e4',\n", " 'teille',\n", " 'he',\n", " 'heid\u00e4n',\n", " 'heid\u00e4t',\n", " 'heit\u00e4',\n", " 'heiss\u00e4',\n", " 'heist\u00e4',\n", " 'heihin',\n", " 'heill\u00e4',\n", " 'heilt\u00e4',\n", " 'heille',\n", " 't\u00e4m\u00e4',\n", " 't\u00e4m\u00e4n',\n", " 't\u00e4t\u00e4',\n", " 't\u00e4ss\u00e4',\n", " 't\u00e4st\u00e4',\n", " 't\u00e4h\u00e4n',\n", " 'tall\u00e4',\n", " 't\u00e4lt\u00e4',\n", " 't\u00e4lle',\n", " 't\u00e4n\u00e4',\n", " 't\u00e4ksi',\n", " 'tuo',\n", " 'tuon',\n", " 'tuot\u00e4',\n", " 'tuossa',\n", " 'tuosta',\n", " 'tuohon',\n", " 'tuolla',\n", " 'tuolta',\n", " 'tuolle',\n", " 'tuona',\n", " 'tuoksi',\n", " 'se',\n", " 'sen',\n", " 'sit\u00e4',\n", " 'siin\u00e4',\n", " 'siit\u00e4',\n", " 'siihen',\n", " 'sill\u00e4',\n", " 'silt\u00e4',\n", " 'sille',\n", " 'sin\u00e4',\n", " 'siksi',\n", " 'n\u00e4m\u00e4',\n", " 'n\u00e4iden',\n", " 'n\u00e4it\u00e4',\n", " 'n\u00e4iss\u00e4',\n", " 'n\u00e4ist\u00e4',\n", " 'n\u00e4ihin',\n", " 'n\u00e4ill\u00e4',\n", " 'n\u00e4ilt\u00e4',\n", " 'n\u00e4ille',\n", " 'n\u00e4in\u00e4',\n", " 'n\u00e4iksi',\n", " 'nuo',\n", " 'noiden',\n", " 'noita',\n", " 'noissa',\n", " 'noista',\n", " 'noihin',\n", " 'noilla',\n", " 'noilta',\n", " 'noille',\n", " 'noina',\n", " 'noiksi',\n", " 'ne',\n", " 'niiden',\n", " 'niit\u00e4',\n", " 'niiss\u00e4',\n", " 'niist\u00e4',\n", " 'niihin',\n", " 'niill\u00e4',\n", " 'niilt\u00e4',\n", " 'niille',\n", " 'niin\u00e4',\n", " 'niiksi',\n", " 'kuka',\n", " 'kenen',\n", " 'kenet',\n", " 'ket\u00e4',\n", " 'keness\u00e4',\n", " 'kenest\u00e4',\n", " 'keneen',\n", " 'kenell\u00e4',\n", " 'kenelt\u00e4',\n", " 'kenelle',\n", " 'kenen\u00e4',\n", " 'keneksi',\n", " 'ketk\u00e4',\n", " 'keiden',\n", " 'ketk\u00e4',\n", " 'keit\u00e4',\n", " 'keiss\u00e4',\n", " 'keist\u00e4',\n", " 'keihin',\n", " 'keill\u00e4',\n", " 'keilt\u00e4',\n", " 'keille',\n", " 'kein\u00e4',\n", " 'keiksi',\n", " 'mik\u00e4',\n", " 'mink\u00e4',\n", " 'mink\u00e4',\n", " 'mit\u00e4',\n", " 'miss\u00e4',\n", " 'mist\u00e4',\n", " 'mihin',\n", " 'mill\u00e4',\n", " 'milt\u00e4',\n", " 'mille',\n", " 'min\u00e4',\n", " 'miksi',\n", " 'mitk\u00e4',\n", " 'joka',\n", " 'jonka',\n", " 'jota',\n", " 'jossa',\n", " 'josta',\n", " 'johon',\n", " 'jolla',\n", " 'jolta',\n", " 'jolle',\n", " 'jona',\n", " 'joksi',\n", " 'jotka',\n", " 'joiden',\n", " 'joita',\n", " 'joissa',\n", " 'joista',\n", " 'joihin',\n", " 'joilla',\n", " 'joilta',\n", " 'joille',\n", " 'joina',\n", " 'joiksi',\n", " 'ett\u00e4',\n", " 'ja',\n", " 'jos',\n", " 'koska',\n", " 'kuin',\n", " 'mutta',\n", " 'niin',\n", " 'sek\u00e4',\n", " 'sill\u00e4',\n", " 'tai',\n", " 'vaan',\n", " 'vai',\n", " 'vaikka',\n", " 'kanssa',\n", " 'mukaan',\n", " 'noin',\n", " 'poikki',\n", " 'yli',\n", " 'kun',\n", " 'niin',\n", " 'nyt',\n", " 'itse',\n", " 'au',\n", " 'aux',\n", " 'avec',\n", " 'ce',\n", " 'ces',\n", " 'dans',\n", " 'de',\n", " 'des',\n", " 'du',\n", " 'elle',\n", " 'en',\n", " 'et',\n", " 'eux',\n", " 'il',\n", " 'je',\n", " 'la',\n", " 'le',\n", " 'leur',\n", " 'lui',\n", " 'ma',\n", " 'mais',\n", " 'me',\n", " 'm\u00eame',\n", " 'mes',\n", " 'moi',\n", " 'mon',\n", " 'ne',\n", " 'nos',\n", " 'notre',\n", " 'nous',\n", " 'on',\n", " 'ou',\n", " 'par',\n", " 'pas',\n", " 'pour',\n", " 'qu',\n", " 'que',\n", " 'qui',\n", " 'sa',\n", " 'se',\n", " 'ses',\n", " 'son',\n", " 'sur',\n", " 'ta',\n", " 'te',\n", " 'tes',\n", " 'toi',\n", " 'ton',\n", " 'tu',\n", " 'un',\n", " 'une',\n", " 'vos',\n", " 'votre',\n", " 'vous',\n", " 'c',\n", " 'd',\n", " 'j',\n", " 'l',\n", " '\u00e0',\n", " 'm',\n", " 'n',\n", " 's',\n", " 't',\n", " 'y',\n", " '\u00e9t\u00e9',\n", " '\u00e9t\u00e9e',\n", " '\u00e9t\u00e9es',\n", " '\u00e9t\u00e9s',\n", " '\u00e9tant',\n", " '\u00e9tante',\n", " '\u00e9tants',\n", " '\u00e9tantes',\n", " 'suis',\n", " 'es',\n", " 'est',\n", " 'sommes',\n", " '\u00eates',\n", " 'sont',\n", " 'serai',\n", " 'seras',\n", " 'sera',\n", " 'serons',\n", " 'serez',\n", " 'seront',\n", " 'serais',\n", " 'serait',\n", " 'serions',\n", " 'seriez',\n", " 'seraient',\n", " '\u00e9tais',\n", " '\u00e9tait',\n", " '\u00e9tions',\n", " '\u00e9tiez',\n", " '\u00e9taient',\n", " 'fus',\n", " 'fut',\n", " 'f\u00fbmes',\n", " 'f\u00fbtes',\n", " 'furent',\n", " 'sois',\n", " 'soit',\n", " 'soyons',\n", " 'soyez',\n", " 'soient',\n", " 'fusse',\n", " 'fusses',\n", " 'f\u00fbt',\n", " 'fussions',\n", " 'fussiez',\n", " 'fussent',\n", " 'ayant',\n", " 'ayante',\n", " 'ayantes',\n", " 'ayants',\n", " 'eu',\n", " 'eue',\n", " 'eues',\n", " 'eus',\n", " 'ai',\n", " 'as',\n", " 'avons',\n", " 'avez',\n", " 'ont',\n", " 'aurai',\n", " 'auras',\n", " 'aura',\n", " 'aurons',\n", " 'aurez',\n", " 'auront',\n", " 'aurais',\n", " 'aurait',\n", " 'aurions',\n", " 'auriez',\n", " 'auraient',\n", " 'avais',\n", " 'avait',\n", " 'avions',\n", " 'aviez',\n", " 'avaient',\n", " 'eut',\n", " 'e\u00fbmes',\n", " 'e\u00fbtes',\n", " 'eurent',\n", " 'aie',\n", " 'aies',\n", " 'ait',\n", " 'ayons',\n", " 'ayez',\n", " 'aient',\n", " 'eusse',\n", " 'eusses',\n", " 'e\u00fbt',\n", " 'eussions',\n", " 'eussiez',\n", " 'eussent',\n", " 'aber',\n", " 'alle',\n", " 'allem',\n", " 'allen',\n", " 'aller',\n", " 'alles',\n", " 'als',\n", " 'also',\n", " 'am',\n", " 'an',\n", " 'ander',\n", " 'andere',\n", " 'anderem',\n", " 'anderen',\n", " 'anderer',\n", " 'anderes',\n", " 'anderm',\n", " 'andern',\n", " 'anderr',\n", " 'anders',\n", " 'auch',\n", " 'auf',\n", " 'aus',\n", " 'bei',\n", " 'bin',\n", " 'bis',\n", " 'bist',\n", " 'da',\n", " 'damit',\n", " 'dann',\n", " 'der',\n", " 'den',\n", " 'des',\n", " 'dem',\n", " 'die',\n", " 'das',\n", " 'da\u00df',\n", " 'derselbe',\n", " 'derselben',\n", " 'denselben',\n", " 'desselben',\n", " 'demselben',\n", " 'dieselbe',\n", " 'dieselben',\n", " 'dasselbe',\n", " 'dazu',\n", " 'dein',\n", " 'deine',\n", " 'deinem',\n", " 'deinen',\n", " 'deiner',\n", " 'deines',\n", " 'denn',\n", " 'derer',\n", " 'dessen',\n", " 'dich',\n", " 'dir',\n", " 'du',\n", " 'dies',\n", " 'diese',\n", " 'diesem',\n", " 'diesen',\n", " 'dieser',\n", " 'dieses',\n", " 'doch',\n", " 'dort',\n", " 'durch',\n", " 'ein',\n", " 'eine',\n", " 'einem',\n", " 'einen',\n", " 'einer',\n", " 'eines',\n", " 'einig',\n", " 'einige',\n", " 'einigem',\n", " 'einigen',\n", " 'einiger',\n", " 'einiges',\n", " 'einmal',\n", " 'er',\n", " 'ihn',\n", " 'ihm',\n", " 'es',\n", " 'etwas',\n", " 'euer',\n", " 'eure',\n", " 'eurem',\n", " 'euren',\n", " 'eurer',\n", " 'eures',\n", " 'f\u00fcr',\n", " 'gegen',\n", " 'gewesen',\n", " 'hab',\n", " 'habe',\n", " 'haben',\n", " 'hat',\n", " 'hatte',\n", " 'hatten',\n", " 'hier',\n", " 'hin',\n", " 'hinter',\n", " 'ich',\n", " 'mich',\n", " 'mir',\n", " 'ihr',\n", " 'ihre',\n", " 'ihrem',\n", " 'ihren',\n", " 'ihrer',\n", " 'ihres',\n", " 'euch',\n", " 'im',\n", " 'in',\n", " 'indem',\n", " 'ins',\n", " 'ist',\n", " 'jede',\n", " 'jedem',\n", " 'jeden',\n", " 'jeder',\n", " 'jedes',\n", " 'jene',\n", " 'jenem',\n", " 'jenen',\n", " 'jener',\n", " 'jenes',\n", " 'jetzt',\n", " 'kann',\n", " 'kein',\n", " 'keine',\n", " 'keinem',\n", " 'keinen',\n", " 'keiner',\n", " 'keines',\n", " 'k\u00f6nnen',\n", " 'k\u00f6nnte',\n", " 'machen',\n", " 'man',\n", " 'manche',\n", " 'manchem',\n", " 'manchen',\n", " 'mancher',\n", " 'manches',\n", " 'mein',\n", " 'meine',\n", " 'meinem',\n", " 'meinen',\n", " 'meiner',\n", " 'meines',\n", " 'mit',\n", " 'muss',\n", " 'musste',\n", " 'nach',\n", " 'nicht',\n", " 'nichts',\n", " 'noch',\n", " 'nun',\n", " 'nur',\n", " 'ob',\n", " 'oder',\n", " 'ohne',\n", " 'sehr',\n", " 'sein',\n", " 'seine',\n", " 'seinem',\n", " 'seinen',\n", " 'seiner',\n", " 'seines',\n", " 'selbst',\n", " 'sich',\n", " 'sie',\n", " 'ihnen',\n", " 'sind',\n", " 'so',\n", " 'solche',\n", " 'solchem',\n", " 'solchen',\n", " 'solcher',\n", " 'solches',\n", " 'soll',\n", " 'sollte',\n", " 'sondern',\n", " 'sonst',\n", " '\u00fcber',\n", " 'um',\n", " 'und',\n", " 'uns',\n", " 'unse',\n", " 'unsem',\n", " 'unsen',\n", " 'unser',\n", " 'unses',\n", " 'unter',\n", " 'viel',\n", " 'vom',\n", " 'von',\n", " 'vor',\n", " 'w\u00e4hrend',\n", " 'war',\n", " 'waren',\n", " 'warst',\n", " 'was',\n", " 'weg',\n", " 'weil',\n", " 'weiter',\n", " 'welche',\n", " 'welchem',\n", " 'welchen',\n", " 'welcher',\n", " 'welches',\n", " 'wenn',\n", " 'werde',\n", " 'werden',\n", " 'wie',\n", " 'wieder',\n", " 'will',\n", " 'wir',\n", " 'wird',\n", " 'wirst',\n", " 'wo',\n", " 'wollen',\n", " 'wollte',\n", " 'w\u00fcrde',\n", " 'w\u00fcrden',\n", " 'zu',\n", " 'zum',\n", " 'zur',\n", " 'zwar',\n", " 'zwischen',\n", " 'a',\n", " 'ahogy',\n", " 'ahol',\n", " 'aki',\n", " 'akik',\n", " 'akkor',\n", " 'alatt',\n", " '\u00e1ltal',\n", " '\u00e1ltal\u00e1ban',\n", " 'amely',\n", " 'amelyek',\n", " 'amelyekben',\n", " 'amelyeket',\n", " 'amelyet',\n", " 'amelynek',\n", " 'ami',\n", " 'amit',\n", " 'amolyan',\n", " 'am\u00edg',\n", " 'amikor',\n", " '\u00e1t',\n", " 'abban',\n", " 'ahhoz',\n", " 'annak',\n", " 'arra',\n", " 'arr\u00f3l',\n", " 'az',\n", " 'azok',\n", " 'azon',\n", " 'azt',\n", " 'azzal',\n", " ...]"]}, "execution_count": 14}], "execution_count": 14}, {"cell_type": "markdown", "metadata": {}, "source": ["Great! You can see that the stop words list is actually very extensive. That's because it contains stopwords that are in most languages! So if you decide to analyze text in a non-English language, NLTK already has you covered.\n", "\n", "Now let's check to see what is left of our example text after we remove the stopwords."]}, {"cell_type": "code", "metadata": {"collapsed": false}, "source": ["print([word for word in example_words if word not in stopwords.words()])"], "outputs": [{"output_type": "stream", "name": "stdout", "text": ["['Adam', 'totally', 'cool', 'You', 'class']\n"]}], "execution_count": 15}, {"cell_type": "markdown", "metadata": {}, "source": ["You can see that it really cut down the entire list of words to basically just the nouns, adjectives, and modifiers. \n", "\n", "Removing stopwords is extremely important when we're trying to get to the real meat of a text. \n", "\n", "So let's move onto actual text and apply these principles. Load Othello and get Hamlet and Iago's speaking parts.\n", "\n", "Now let's work on the actual text. Extract Othello and Iago's dialogue using our code from the morning:"]}, {"cell_type": "code", "metadata": {"collapsed": false}, "source": ["#Extract Othello\n"], "outputs": [], "execution_count": 15}, {"cell_type": "markdown", "metadata": {"collapsed": true}, "source": ["Excellent, now let's actually remove all of the stopwords and see what that does to the dialogue size of the two characters."]}, {"cell_type": "code", "metadata": {"collapsed": false}, "source": ["cleaned_othello = [word for word in othellos_dialogue if word not in stopwords.words()]\n", "cleaned_iago = [word for word in iagos_dialogue if word not in stopwords.words()]\n", "\n", "print(\"Othello dialogue size\", len( othellos_dialogue))\n", "print(\"Othello dialogue size without stopwords\", len( cleaned_othello))\n", "print('----')\n", "print(\"Iago dialogue size\", len( iagos_dialogue))\n", "print(\"Iago dialogue size without stopwords\", len( cleaned_iago))"], "outputs": [{"output_type": "stream", "name": "stdout", "text": ["Othello dialogue size 6284\n", "Othello dialogue size without stopwords 3124\n", "----\n", "Iago dialogue size 8330\n", "Iago dialogue size without stopwords 3920\n"]}], "execution_count": 18}, {"cell_type": "markdown", "metadata": {"collapsed": true}, "source": ["We see that there is a non-trivial reduction in the number of words spoken for each character (which should help in further processing!)\n", "\n", "Now what does the distribution of sentiment look like for each of the two characters? Plot the two distributions in separate subplots."]}, {"cell_type": "code", "metadata": {"collapsed": true}, "source": ["###Place your code here\n"], "outputs": [], "execution_count": 18}, {"cell_type": "markdown", "metadata": {"collapsed": true}, "source": ["And they look almost exactly the same! However, we can tell that there is a nearly 20% difference in the averages.\n", "\n", "The distribution of sentiment scores is interesting, but does not give us a picture of the arc of the story.  To extract that information, we need to keep track of when each word is spoken."]}, {"cell_type": "code", "metadata": {"collapsed": true}, "source": ["###Sentiment over time for Iago and Othello\n"], "outputs": [], "execution_count": null}, {"cell_type": "markdown", "metadata": {}, "source": ["Let's focus on Othelo first. Interesting! We can see that the first 150 scored words uttered by Othello are quite positive. The next 150 are only slightly positive, and the last 250 words have a slight negative bias. \n", "\n", "It might be time to actually to refresh ourselves on the [story of Othello](https://en.wikipedia.org/wiki/Othello)....\n", "\n", "Iago's speech has a different arc. The positivity in his utterances comes in spikes. The rest of the time he keeps near neutrality of sentiment.  As if he was hiding his feelings...\n", "\n", "How does this compare to the whole text?"]}, {"cell_type": "code", "metadata": {"collapsed": true}, "source": ["### Place your code here\n", "\n"], "outputs": [], "execution_count": null}, {"cell_type": "markdown", "metadata": {}, "source": ["Without a reference point (i.e., comparing one character to another), it's acutally a bit easier to see the arc of the story in the rolling mean. \n", "\n", "Here we can see that Othello lives up to its label as a tragedy. Near the end of the labeled words there is a steep decline in the sentiment of words used.\n", "\n", "Let's see if we can see more of a difference between Othello and Iago using the rolling mean:"]}, {"cell_type": "code", "metadata": {"collapsed": true}, "source": ["#Your code here\n"], "outputs": [], "execution_count": 23}, {"cell_type": "markdown", "metadata": {}, "source": ["Ah! That's actually a much easier way to intuit the dialogue of each individual character!\n", "\n", "Let's actually compare the dialogue of every character in Othello. "]}, {"cell_type": "code", "metadata": {"collapsed": true}, "source": ["#Your code here\n"], "outputs": [], "execution_count": 69}, {"cell_type": "markdown", "metadata": {}, "source": ["Well, I guess we can see that a few characters had quite a poor turn near the end there!"]}, {"cell_type": "markdown", "metadata": {}, "source": ["How well does our technique work with a different Shakespeare play, say \"The Merchant of Venice\".\n", "\n", "Refactor the original code to extract Othelo and make it pull out the character dialogue of any play."]}, {"cell_type": "code", "metadata": {"collapsed": false}, "source": ["#Place your code here\n"], "outputs": [], "execution_count": 113}, {"cell_type": "code", "metadata": {"collapsed": true}, "source": [], "outputs": [], "execution_count": null}], "metadata": {"kernelspec": {"language": "python", "name": "Python [Root]", "display_name": "Python [Root]"}, "anaconda-cloud": {}, "language_info": {"mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "file_extension": ".py", "version": "3.5.1", "codemirror_mode": {"name": "ipython", "version": 3}}}, "nbformat_minor": 0, "nbformat": 4}
